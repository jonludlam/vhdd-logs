[20131218T17:44:29.038Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|0||watchdog] (Re)starting vhdd...
[20131218T17:44:29.038Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|0||watchdog] Child vhdd is: 27222
[20131218T17:44:29.039Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|0||http] Establishing inet domain server
[20131218T17:44:29.040Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|0||attachments] Ignoring ENOENT while reading attachments file
[20131218T17:44:29.042Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|9 inet-rpc||http] Request { frame = false; method = POST; uri = /internal; query = [  ]; content_length = [ 57 ]; transfer encoding = ; version = 1.0; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = ; user_agent = xen-api-libs/1.0 }
[20131218T17:44:29.042Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|9 inet-rpc||vhdd] Internal handler
[20131218T17:44:29.042Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|9 inet-rpc||vhdd] Call={"method": "Debug.get_pid", "params": [null], "id": 2438}
[20131218T17:44:29.042Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|9 inet-rpc||vhdd] Response: {"result": 27222, "error": null, "id": 0}
[20131218T17:44:29.044Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|12 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 204 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:29.044Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|12 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:29.044Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|12 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>SR.list</methodName><params><param><value><struct><member><name>dbg</name><value>wait_for_start</value></member></struct></value></param></params></methodCall>
[20131218T17:44:29.045Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|12 inet-rpc|9934bead-5814-41fe-ae05-2f82fe0a75df|vhdd] Response: (omitted)
[20131218T17:44:29.046Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 574 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:29.046Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:29.046Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>SR.create</methodName><params><param><value><struct><member><name>dbg</name><value>create_and_attach</value></member><member><name>sr</name><value>1</value></member><member><name>device_config</name><value><struct><member><name>SRmaster</name><value>true</value></member><member><name>device</name><value>/dev/dummy</value></member><member><name>reservation_mode</name><value>thin</value></member></struct></value></member><member><name>physical_size</name><value>0</value></member></struct></value></param></params></methodCall>
[20131218T17:44:29.046Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc|692aabc6-1a85-4514-afd7-86bca835897c|mlvm] write_label_and_pv_header:
PV header:
pvh_id: Np3GjL-QHMs-pLNs-MZnG-jWQc-3jQ2-gGu2I1
pvh_device_size: 1099511627776
pvh_areas1: {offset=10551296,size=0}
pvh_areas2: {offset=4096,size=10547200}

[20131218T17:44:29.081Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc|692aabc6-1a85-4514-afd7-86bca835897c|mlvm] Writing MDA header
[20131218T17:44:29.081Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc|692aabc6-1a85-4514-afd7-86bca835897c|mlvm] Writing: checksum: 0
magic:  LVM2 x[5A%r0N*>
version: 1
start: 4096
size: 10485760
raw_locns:[{offset:512,size:0,checksum:0,filler:0}]

[20131218T17:44:29.088Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc|692aabc6-1a85-4514-afd7-86bca835897c|mlvm] PVs created
[20131218T17:44:29.089Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc|692aabc6-1a85-4514-afd7-86bca835897c|mlvm] write_label_and_pv_header:
PV header:
pvh_id: Np3GjL-QHMs-pLNs-MZnG-jWQc-3jQ2-gGu2I1
pvh_device_size: 1099511627776
pvh_areas1: {offset=10551296,size=0}
pvh_areas2: {offset=4096,size=10547200}

[20131218T17:44:29.093Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc|692aabc6-1a85-4514-afd7-86bca835897c|mlvm] Writing MDA header
[20131218T17:44:29.093Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc|692aabc6-1a85-4514-afd7-86bca835897c|mlvm] Writing: checksum: 0
magic:  LVM2 x[5A%r0N*>
version: 1
start: 4096
size: 10485760
raw_locns:[{offset:512,size:511,checksum:-1798829574,filler:0}]

[20131218T17:44:29.094Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc|692aabc6-1a85-4514-afd7-86bca835897c|mlvm] VG created
[20131218T17:44:29.094Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc|692aabc6-1a85-4514-afd7-86bca835897c|vhdd] Response: (omitted)
[20131218T17:44:29.099Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 515 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:29.100Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:29.100Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>SR.attach</methodName><params><param><value><struct><member><name>dbg</name><value>create_and_attach</value></member><member><name>sr</name><value>1</value></member><member><name>device_config</name><value><struct><member><name>SRmaster</name><value>true</value></member><member><name>device</name><value>/dev/dummy</value></member><member><name>reservation_mode</name><value>thin</value></member></struct></value></member></struct></value></param></params></methodCall>
[20131218T17:44:29.100Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|lvmabs] init_lvm: Loading Vg from devices list: [/dev/dummy]
[20131218T17:44:29.100Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] Vg.load
[20131218T17:44:29.100Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] Label found: 
Label header:
id: LABELONE
sector: 1
crc: -498900674
offset: 32
ty: LVM2 001

PV Header:
pvh_id: Np3GjL-QHMs-pLNs-MZnG-jWQc-3jQ2-gGu2I1
pvh_device_size: 1099511627776
pvh_areas1: {offset=10551296,size=0}
pvh_areas2: {offset=4096,size=10547200}



[20131218T17:44:29.101Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|lvmabs] init_lvm: Vg loaded:
[20131218T17:44:29.101Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|lvmabs] VG_XenStorage-1 {
id = "XyZDQR-mHMx-gpfs-RQXl-UM87-dtIn-nVrTQW"
seqno = 1
status = ["READ", "WRITE"]
extent_size = 8192
max_lv = 0
max_pv = 0

physical_volumes {

pv0 {
id = "Np3GjL-QHMs-pLNs-MZnG-jWQc-3jQ2-gGu2I1"
device = "/dev/dummy"

status = ["ALLOCATABLE"]
dev_size = 2147483648
pe_start = 20608
pe_count = 262141
}
}

logical_volumes {
}
}
# Generated by MLVM version 0.1: 

contents = "Text Format Volume Group"
version = 1

description = ""

creation_host = "<need uname!>"
creation_time = 1387388669


[20131218T17:44:29.101Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] write_label_and_pv_header:
PV header:
pvh_id: Np3GjL-QHMs-pLNs-MZnG-jWQc-3jQ2-gGu2I1
pvh_device_size: 1099511627776
pvh_areas1: {offset=10551296,size=0}
pvh_areas2: {offset=4096,size=10547200}

[20131218T17:44:29.102Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] Writing MDA header
[20131218T17:44:29.102Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] Writing: checksum: 776715836
magic:  LVM2 x[5A%r0N*>
version: 1
start: 4096
size: 10485760
raw_locns:[{offset:1024,size:738,checksum:280846103,filler:0}]

[20131218T17:44:29.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|lvmabs] init_lvm: Redo log initialized:
[20131218T17:44:29.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|lvmabs] VG_XenStorage-1 {
id = "XyZDQR-mHMx-gpfs-RQXl-UM87-dtIn-nVrTQW"
seqno = 2
status = ["READ", "WRITE"]
extent_size = 8192
max_lv = 0
max_pv = 0

physical_volumes {

pv0 {
id = "Np3GjL-QHMs-pLNs-MZnG-jWQc-3jQ2-gGu2I1"
device = "/dev/dummy"

status = ["ALLOCATABLE"]
dev_size = 2147483648
pe_start = 20608
pe_count = 262141
}
}

logical_volumes {

mlvm_redo_log {
id = "2wCeio-XPd7-MZeD-q7gi-9mw3-COt5-eHSUx6"
status = ["READ", "VISIBLE"]
segment_count = 1

segment1 {
start_extent = 0
extent_count = 1

type = "striped"
stripe_count = 1	#linear

stripes = [
"pv0", 0
]
}
}
}
}
# Generated by MLVM version 0.1: 

contents = "Text Format Volume Group"
version = 1

description = ""

creation_host = "<need uname!>"
creation_time = 1387388669


[20131218T17:44:29.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] add_pv_id_info: Got mutex
[20131218T17:44:29.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] add_pv_id_info: Released mutex
[20131218T17:44:29.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|vhdSlave] VhdSlave.SR.attach
[20131218T17:44:29.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|tapdisk] Tapdisk.scan
[20131218T17:44:29.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|tapdisk] parse_tapdev_link: ..
[20131218T17:44:29.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|tapdisk] parse_tapdev_link: .
[20131218T17:44:29.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|attachments] attach as slave: 1
[20131218T17:44:29.104Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|attachments] Ignoring ENOENT while reading attachments file
[20131218T17:44:29.104Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|vhdsm] mode=Master
[20131218T17:44:29.104Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|vhdmaster] m_rolling_upgrade=false
[20131218T17:44:29.104Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|lvmabs] init_lvm: Loading Vg from devices list: [/dev/dummy]
[20131218T17:44:29.104Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] Vg.load
[20131218T17:44:29.104Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] Label found: 
Label header:
id: LABELONE
sector: 1
crc: -498900674
offset: 32
ty: LVM2 001

PV Header:
pvh_id: Np3GjL-QHMs-pLNs-MZnG-jWQc-3jQ2-gGu2I1
pvh_device_size: 1099511627776
pvh_areas1: {offset=10551296,size=0}
pvh_areas2: {offset=4096,size=10547200}



[20131218T17:44:29.105Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] Allocations for lv mlvm_redo_log:
(pv0: [0,1])

[20131218T17:44:29.105Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] Redo.read
[20131218T17:44:29.105Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] start_ofs: 12 end_ofs: 12 size: 0
[20131218T17:44:29.105Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] Reading from pos: 0
[20131218T17:44:29.105Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] Redo.read finished
[20131218T17:44:29.105Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|lvmabs] init_lvm: Vg loaded:
[20131218T17:44:29.105Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|lvmabs] VG_XenStorage-1 {
id = "XyZDQR-mHMx-gpfs-RQXl-UM87-dtIn-nVrTQW"
seqno = 2
status = ["READ", "WRITE"]
extent_size = 8192
max_lv = 0
max_pv = 0

physical_volumes {

pv0 {
id = "Np3GjL-QHMs-pLNs-MZnG-jWQc-3jQ2-gGu2I1"
device = "/dev/dummy"

status = ["ALLOCATABLE"]
dev_size = 2147483648
pe_start = 20608
pe_count = 262141
}
}

logical_volumes {

mlvm_redo_log {
id = "2wCeio-XPd7-MZeD-q7gi-9mw3-COt5-eHSUx6"
status = ["READ", "VISIBLE"]
segment_count = 1

segment1 {
start_extent = 0
extent_count = 1

type = "striped"
stripe_count = 1	#linear

stripes = [
"pv0", 0
]
}
}
}
}
# Generated by MLVM version 0.1: 

contents = "Text Format Volume Group"
version = 1

description = ""

creation_host = "<need uname!>"
creation_time = 1387388669


[20131218T17:44:29.105Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|lvmabs] init_lvm: Redo log initialized:
[20131218T17:44:29.105Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|lvmabs] VG_XenStorage-1 {
id = "XyZDQR-mHMx-gpfs-RQXl-UM87-dtIn-nVrTQW"
seqno = 2
status = ["READ", "WRITE"]
extent_size = 8192
max_lv = 0
max_pv = 0

physical_volumes {

pv0 {
id = "Np3GjL-QHMs-pLNs-MZnG-jWQc-3jQ2-gGu2I1"
device = "/dev/dummy"

status = ["ALLOCATABLE"]
dev_size = 2147483648
pe_start = 20608
pe_count = 262141
}
}

logical_volumes {

mlvm_redo_log {
id = "2wCeio-XPd7-MZeD-q7gi-9mw3-COt5-eHSUx6"
status = ["READ", "VISIBLE"]
segment_count = 1

segment1 {
start_extent = 0
extent_count = 1

type = "striped"
stripe_count = 1	#linear

stripes = [
"pv0", 0
]
}
}
}
}
# Generated by MLVM version 0.1: 

contents = "Text Format Volume Group"
version = 1

description = ""

creation_host = "<need uname!>"
creation_time = 1387388669


[20131218T17:44:29.105Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|vhdmaster] container initialised
[20131218T17:44:29.105Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|scan] scan
[20131218T17:44:29.105Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|lvmabs] operating on vg: VG_XenStorage-1 lv: mlvm_redo_log
[20131218T17:44:29.106Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|lvmabs] operating on vg: VG_XenStorage-1 lv: mlvm_redo_log
[20131218T17:44:29.106Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] Using dm_name=0dc95fba-edbb-43ce-bd52-be9c2193612d (use_tmp=true)
[20131218T17:44:29.106Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|scan] Reading VHD: /tmp/dummytest/1/dev/mapper/0dc95fba-edbb-43ce-bd52-be9c2193612d
[20131218T17:44:29.106Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] LVM REDO: 000000000113„•¦¾   ]      -   $ B 0host_attachments 	&55OJd5-efrG-ACly-Deta-iTZJ-qMeN-hkeL9P  #pv0 _j        _j        @
[20131218T17:44:29.106Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|lvmabs] operating on vg: VG_XenStorage-1 lv: host_attachments
[20131218T17:44:29.106Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] Using dm_name=05a55ca3-d260-45d1-a9b8-f5830781d363 (use_tmp=true)
[20131218T17:44:29.107Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|lvmabs] operating on vg: VG_XenStorage-1 lv: host_attachments
[20131218T17:44:29.107Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] attach_lv: Got the mutex
[20131218T17:44:29.107Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] LV VG_XenStorage--1-host_attachments not attached: attaching. refcount now 1
[20131218T17:44:29.107Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] Using dm_name=VG_XenStorage--1-host_attachments (use_tmp=false)
[20131218T17:44:29.107Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] attach_lv: released the mutex
[20131218T17:44:29.107Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] Remove LV: refcount for dm=VG_XenStorage--1-host_attachments is now 0
[20131218T17:44:29.107Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] Removing LV=VG_XenStorage--1-host_attachments
[20131218T17:44:29.108Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] LVM REDO: 000000000115„•¦¾   _      -   $ C 2id_to_leaf_mapping 	&8SjmGP-nL7P-ZE64-6F8k-zRnE-FCOM-hT5tMu  #pv0 _j        _j        @
[20131218T17:44:29.108Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|lvmabs] operating on vg: VG_XenStorage-1 lv: id_to_leaf_mapping
[20131218T17:44:29.108Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] Using dm_name=e3ef37dd-ffdb-4fee-984b-10d8d1aed1bd (use_tmp=true)
[20131218T17:44:29.108Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|lvmabs] operating on vg: VG_XenStorage-1 lv: id_to_leaf_mapping
[20131218T17:44:29.108Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] attach_lv: Got the mutex
[20131218T17:44:29.108Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] LV VG_XenStorage--1-id_to_leaf_mapping not attached: attaching. refcount now 1
[20131218T17:44:29.108Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] Using dm_name=VG_XenStorage--1-id_to_leaf_mapping (use_tmp=false)
[20131218T17:44:29.108Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] attach_lv: released the mutex
[20131218T17:44:29.108Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] Remove LV: refcount for dm=VG_XenStorage--1-id_to_leaf_mapping is now 0
[20131218T17:44:29.109Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] Removing LV=VG_XenStorage--1-id_to_leaf_mapping
[20131218T17:44:29.109Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|vhdmaster] Selected provisioning policy: Thin
[20131218T17:44:29.109Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|lvmabs] operating on vg: VG_XenStorage-1 lv: host_attachments
[20131218T17:44:29.109Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] attach_lv: Got the mutex
[20131218T17:44:29.109Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] LV VG_XenStorage--1-host_attachments not attached: attaching. refcount now 1
[20131218T17:44:29.109Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] Using dm_name=VG_XenStorage--1-host_attachments (use_tmp=false)
[20131218T17:44:29.109Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] attach_lv: released the mutex
[20131218T17:44:29.109Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] Remove LV: refcount for dm=VG_XenStorage--1-host_attachments is now 0
[20131218T17:44:29.109Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] Removing LV=VG_XenStorage--1-host_attachments
[20131218T17:44:29.109Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|vhdmaster] Recovering any slaves
[20131218T17:44:29.109Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|nmutex] wait: reason=Retrieving the hashtbl of attached hosts
[20131218T17:44:29.109Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|vhdmaster] About to get_localhost()
[20131218T17:44:29.109Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|vhdmaster] Creating the attach_part_two thread
[20131218T17:44:29.109Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|vhdmaster] About to iterate over attached slaves
[20131218T17:44:29.110Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|15||vhdmaster] attach_part_two thread created
[20131218T17:44:29.110Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|vhdSlave] Registering with master
[20131218T17:44:29.110Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|15||nmutex] wait: reason=Checking whether resync is required
[20131218T17:44:29.110Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|nmutex] wait: reason=Finding all attached/activated VDIs
[20131218T17:44:29.110Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|15||vhdmaster] Attach part two
[20131218T17:44:29.110Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|vhdmaster] Attach from host: 1, ip: 127.0.0.1
[20131218T17:44:29.110Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|slave_sr_attachments] Slave SR attach
[20131218T17:44:29.110Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|15||nmutex] wait: reason=Getting all the leaf infos
[20131218T17:44:29.110Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|nmutex] wait: reason=Adding host to the attached_hosts
[20131218T17:44:29.110Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|15||vhdmaster] Resolving map inconsistencies
[20131218T17:44:29.110Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|lvmabs] operating on vg: VG_XenStorage-1 lv: host_attachments
[20131218T17:44:29.110Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|15||vhdmaster] Resolved
[20131218T17:44:29.110Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] attach_lv: Got the mutex
[20131218T17:44:29.110Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|15||nmutex] wait: reason=setting coalesce_in_progress flag
[20131218T17:44:29.111Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] LV VG_XenStorage--1-host_attachments not attached: attaching. refcount now 1
[20131218T17:44:29.111Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|15||nmutex] wait: reason=Unsetting coalesce_in_progress flag
[20131218T17:44:29.111Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] Using dm_name=VG_XenStorage--1-host_attachments (use_tmp=false)
[20131218T17:44:29.111Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|15||nmutex] About to broadcast
[20131218T17:44:29.111Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] attach_lv: released the mutex
[20131218T17:44:29.111Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|15||nmutex] Done
[20131218T17:44:29.111Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] Remove LV: refcount for dm=VG_XenStorage--1-host_attachments is now 0
[20131218T17:44:29.111Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] Removing LV=VG_XenStorage--1-host_attachments
[20131218T17:44:29.111Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|nmutex] wait: reason=Resyncing VDI attachments/activations
[20131218T17:44:29.111Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|vhdSlave] Registration functions finished. Setting s_ready=true
[20131218T17:44:29.111Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|vhdsm] s_ready for the slave is: true
[20131218T17:44:29.111Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|lvmabs] operating on vg: VG_XenStorage-1 lv: host_attachments
[20131218T17:44:29.112Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] attach_lv: Got the mutex
[20131218T17:44:29.112Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] LV VG_XenStorage--1-host_attachments not attached: attaching. refcount now 1
[20131218T17:44:29.112Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|mlvm] Using dm_name=VG_XenStorage--1-host_attachments (use_tmp=false)
[20131218T17:44:29.112Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] attach_lv: released the mutex
[20131218T17:44:29.112Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] Remove LV: refcount for dm=VG_XenStorage--1-host_attachments is now 0
[20131218T17:44:29.112Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|host] Removing LV=VG_XenStorage--1-host_attachments
[20131218T17:44:29.113Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|fe794ce8-b2c6-4b02-a409-7659846c42d4|vhdd] Response: (omitted)
[20131218T17:44:29.125Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|16 inet-rpc||http] Request { frame = false; method = POST; uri = /internal; query = [  ]; content_length = [ 55 ]; transfer encoding = ; version = 1.0; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = ; user_agent = xen-api-libs/1.0 }
[20131218T17:44:29.125Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|16 inet-rpc||vhdd] Internal handler
[20131218T17:44:29.125Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|16 inet-rpc||vhdd] Call={"method": "SR.mode", "params": [{"sr": "1"}], "id": 1}
[20131218T17:44:29.125Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|16 inet-rpc||vhdd] Response: {"result": "Master", "error": null, "id": 0}
[20131218T17:44:29.128Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||http] Request { frame = false; method = POST; uri = /internal; query = [  ]; content_length = [ 137 ]; transfer encoding = ; version = 1.0; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = ; user_agent = xen-api-libs/1.0 }
[20131218T17:44:29.128Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||vhdd] Internal handler
[20131218T17:44:29.128Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||vhdd] Call={"method": "SR.slave_attach", "params": [{"sr": "1", "host": {"h_uuid": "2", "h_ip": "127.0.0.1", "h_port": 4095}, "vdis": {}}], "id": 2}
[20131218T17:44:29.128Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||vhdmaster] Attach from host: 2, ip: 127.0.0.1
[20131218T17:44:29.128Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||slave_sr_attachments] Slave SR attach
[20131218T17:44:29.128Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||nmutex] wait: reason=Adding host to the attached_hosts
[20131218T17:44:29.129Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||lvmabs] operating on vg: VG_XenStorage-1 lv: host_attachments
[20131218T17:44:29.129Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||host] attach_lv: Got the mutex
[20131218T17:44:29.129Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||host] LV VG_XenStorage--1-host_attachments not attached: attaching. refcount now 1
[20131218T17:44:29.129Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||mlvm] Using dm_name=VG_XenStorage--1-host_attachments (use_tmp=false)
[20131218T17:44:29.129Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||host] attach_lv: released the mutex
[20131218T17:44:29.130Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||host] Remove LV: refcount for dm=VG_XenStorage--1-host_attachments is now 0
[20131218T17:44:29.130Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||host] Removing LV=VG_XenStorage--1-host_attachments
[20131218T17:44:29.130Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||nmutex] wait: reason=Resyncing VDI attachments/activations
[20131218T17:44:29.130Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||vhdd] Response: {"result": "OK", "error": null, "id": 0}
[20131218T17:44:29.132Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 1207 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:29.132Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:29.133Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.create</methodName><params><param><value><struct><member><name>dbg</name><value>create_vdi</value></member><member><name>sr</name><value>1</value></member><member><name>vdi_info</name><value><struct><member><name>vdi</name><value>vdi</value></member><member><name>content_id</name><value></value></member><member><name>name_label</name><value>ftest_vdi</value></member><member><name>name_description</name><value></value></member><member><name>ty</name><value>user</value></member><member><name>metadata_of_pool</name><value></value></member><member><name>is_a_snapshot</name><value><boolean>0</boolean></value></member><member><name>snapshot_time</name><value></value></member><member><name>snapshot_of</name><value></value></member><member><name>read_only</name><value><boolean>0</boolean></value></member><member><name>virtual_size</name><value>52428800</value></member><member><name>physical_utilisation</name><value>0</value></member><member><name>persistent</name><value><boolean>1</boolean></value></member><member><name>sm_config</name><value><struct></struct></value></member></struct></value></member></struct></value></param></params></methodCall>
[20131218T17:44:29.133Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|vhdsm] API call: VDI.create sr=1 size=52428800 sm_config=[]
[20131218T17:44:29.133Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|vhdutil] Dump size: overhead=4312576 phys_size=4312576 virtual_size=52428800 critical_size=109170176
[20131218T17:44:29.133Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|vhdutil] leaf_status: Some false reservation_type: Thin
[20131218T17:44:29.133Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-e906484b-7f75-4b2c-ba81-c966d9c7f7cc
[20131218T17:44:29.133Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|mlvm] LVM REDO: 000000000138„•¦¾   v      3   ' D 	(VHD-e906484b-7f75-4b2c-ba81-c966d9c7f7cc 	&DJQ1gG-gaZv-T82w-GnsB-DplK-DjGr-1pTifR  #pv0 _j        _j        @
[20131218T17:44:29.133Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-e906484b-7f75-4b2c-ba81-c966d9c7f7cc
[20131218T17:44:29.133Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|host] attach_lv: Got the mutex
[20131218T17:44:29.133Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|host] LV VG_XenStorage--1-VHD--e906484b--7f75--4b2c--ba81--c966d9c7f7cc not attached: attaching. refcount now 1
[20131218T17:44:29.134Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|mlvm] Using dm_name=VG_XenStorage--1-VHD--e906484b--7f75--4b2c--ba81--c966d9c7f7cc (use_tmp=false)
[20131218T17:44:29.134Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|host] attach_lv: released the mutex
[20131218T17:44:29.174Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|vhdutil] query_size_vhd: Querying size of VHD 112325cf-1bbc-42c0-aba6-4c9dd3aac69f
[20131218T17:44:29.174Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|vhdutil] query_size_vhd: get_phys_size returned 4311040
[20131218T17:44:29.174Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|vhdutil] query_size_vhd: first_allocated_block=None
[20131218T17:44:29.174Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|vhdutil] query_size_vhd: virtual_size=52428800
[20131218T17:44:29.174Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|nmutex] wait: reason=Adding VHD uid='112325cf-1bbc-42c0-aba6-4c9dd3aac69f'
[20131218T17:44:29.174Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|host] Remove LV: refcount for dm=VG_XenStorage--1-VHD--e906484b--7f75--4b2c--ba81--c966d9c7f7cc is now 0
[20131218T17:44:29.174Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|host] Removing LV=VG_XenStorage--1-VHD--e906484b--7f75--4b2c--ba81--c966d9c7f7cc
[20131218T17:44:29.175Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|nmutex] wait: reason=Adding a new ID to the mapping (df489463-b29f-41f0-a372-95ecca088905->PVhd '112325cf-1bbc-42c0-aba6-4c9dd3aac69f')
[20131218T17:44:29.175Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|lvmabs] operating on vg: VG_XenStorage-1 lv: id_to_leaf_mapping
[20131218T17:44:29.175Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|host] attach_lv: Got the mutex
[20131218T17:44:29.175Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|host] LV VG_XenStorage--1-id_to_leaf_mapping not attached: attaching. refcount now 1
[20131218T17:44:29.175Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|mlvm] Using dm_name=VG_XenStorage--1-id_to_leaf_mapping (use_tmp=false)
[20131218T17:44:29.175Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|host] attach_lv: released the mutex
[20131218T17:44:29.175Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|host] Remove LV: refcount for dm=VG_XenStorage--1-id_to_leaf_mapping is now 0
[20131218T17:44:29.175Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|host] Removing LV=VG_XenStorage--1-id_to_leaf_mapping
[20131218T17:44:29.175Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|55a74294-7fb2-4f83-82d9-d0c8a24da06b|vhdd] Response: (omitted)
[20131218T17:44:29.177Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 486 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:29.177Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:29.177Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.attach</methodName><params><param><value><struct><member><name>dbg</name><value>dbg</value></member><member><name>dp</name><value>df489463-b29f-41f0-a372-95ecca088905</value></member><member><name>sr</name><value>1</value></member><member><name>vdi</name><value>df489463-b29f-41f0-a372-95ecca088905</value></member><member><name>read_write</name><value><boolean>1</boolean></value></member></struct></value></param></params></methodCall>
[20131218T17:44:29.177Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdsm] API call: VDI.attach sr=1 vdi=df489463-b29f-41f0-a372-95ecca088905 writable=true
[20131218T17:44:29.177Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:29.177Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|nmutex] wait: reason=Adding to current_operations
[20131218T17:44:29.177Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdSlave] Checking current ops
[20131218T17:44:29.177Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:29.178Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|nmutex] wait: reason=Finding whether we're already attached
[20131218T17:44:29.178Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|nmutex] wait: reason=Retrieving the hashtbl of attached hosts
[20131218T17:44:29.178Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdmaster] Got to the slave_attach function call
[20131218T17:44:29.178Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:29.178Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|nmutex] wait: reason=Executing with operation '"OpAttaching"'
[20131218T17:44:29.178Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:29.178Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|nmutex] wait: reason=Getting VHD uid='112325cf-1bbc-42c0-aba6-4c9dd3aac69f'
[20131218T17:44:29.178Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdMaster_utils] Resizing VHD uid: 112325cf-1bbc-42c0-aba6-4c9dd3aac69f
[20131218T17:44:29.178Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-e906484b-7f75-4b2c-ba81-c966d9c7f7cc
[20131218T17:44:29.178Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|mlvm] Using dm_name=0a378e06-7aa3-4459-8938-a819e151a006 (use_tmp=true)
[20131218T17:44:29.178Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdutil] Dump size: overhead=4311040 phys_size=4311040 virtual_size=52428800 critical_size=56739840
[20131218T17:44:29.179Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdutil] leaf_status: Some true reservation_type: Thin
[20131218T17:44:29.179Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-e906484b-7f75-4b2c-ba81-c966d9c7f7cc
[20131218T17:44:29.179Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdMaster_utils] new_size=old_size=58720256. Not doing anything
[20131218T17:44:29.179Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|nmutex] wait: reason=Update id_map
[20131218T17:44:29.179Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|locking] update_leaf: vdi_location=df489463-b29f-41f0-a372-95ecca088905
[20131218T17:44:29.179Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|nmutex] wait: reason=Finished op '"OpAttaching"'. Removing from cur
[20131218T17:44:29.179Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|nmutex] About to broadcast
[20131218T17:44:29.179Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|nmutex] Done
[20131218T17:44:29.179Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|nmutex] wait: reason=Getting a copy of a VHD chain
[20131218T17:44:29.179Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-e906484b-7f75-4b2c-ba81-c966d9c7f7cc
[20131218T17:44:29.179Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-e906484b-7f75-4b2c-ba81-c966d9c7f7cc
[20131218T17:44:29.179Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-e906484b-7f75-4b2c-ba81-c966d9c7f7cc
[20131218T17:44:29.179Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdSlave] Got response: leaf=/tmp/dummytest/1//dev/mapper/VG_XenStorage--1-VHD--e906484b--7f75--4b2c--ba81--c966d9c7f7cc
[20131218T17:44:29.179Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:29.179Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|nmutex] wait: reason=Adding to master_approved_ops
[20131218T17:44:29.179Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdSlave] Checking current ops
[20131218T17:44:29.180Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:29.180Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdSlave] LV name: VG_XenStorage--1-VHD--e906484b--7f75--4b2c--ba81--c966d9c7f7cc
[20131218T17:44:29.180Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|host] attach_lv: Got the mutex
[20131218T17:44:29.180Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|host] LV VG_XenStorage--1-VHD--e906484b--7f75--4b2c--ba81--c966d9c7f7cc not attached: attaching. refcount now 1
[20131218T17:44:29.180Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|mlvm] Using dm_name=VG_XenStorage--1-VHD--e906484b--7f75--4b2c--ba81--c966d9c7f7cc (use_tmp=false)
[20131218T17:44:29.180Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|host] attach_lv: released the mutex
[20131218T17:44:29.181Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdSlave] s_mutex lock: attach_from_sai
[20131218T17:44:29.181Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|nmutex] wait: reason=Adding info to s_attached_vdis
[20131218T17:44:29.181Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:29.181Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|nmutex] wait: reason=Removing from master_approved_ops
[20131218T17:44:29.181Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdSlave] Removing my current op
[20131218T17:44:29.181Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:29.181Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|nmutex] About to broadcast
[20131218T17:44:29.182Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|nmutex] Done
[20131218T17:44:29.182Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:29.182Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|nmutex] wait: reason=Removing from current_operations
[20131218T17:44:29.182Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdSlave] Removing my current op
[20131218T17:44:29.182Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:29.182Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|nmutex] About to broadcast
[20131218T17:44:29.182Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|nmutex] Done
[20131218T17:44:29.182Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|0c1fef01-c8e9-41d2-9404-3c3e158e39c8|vhdd] Response: (omitted)
[20131218T17:44:29.185Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc||http] Request { frame = false; method = POST; uri = /internal; query = [  ]; content_length = [ 169 ]; transfer encoding = ; version = 1.0; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = ; user_agent = xen-api-libs/1.0 }
[20131218T17:44:29.185Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc||vhdd] Internal handler
[20131218T17:44:29.185Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc||vhdd] Call={"method": "VDI.slave_attach", "params": [{"host_uuid": "2", "sr": "1", "vdi": "df489463-b29f-41f0-a372-95ecca088905", "writable": true, "is_reattach": false}], "id": 3}
[20131218T17:44:29.185Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc||nmutex] wait: reason=Retrieving the hashtbl of attached hosts
[20131218T17:44:29.185Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc||vhdmaster] Got to the slave_attach function call
[20131218T17:44:29.185Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc||nmutex] wait: reason=Locked get leaf info
[20131218T17:44:29.185Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc||nmutex] wait: reason=Executing with operation '"OpAttaching"'
[20131218T17:44:29.185Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc||nmutex] wait: reason=Locked get leaf info
[20131218T17:44:29.185Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc||nmutex] wait: reason=Update id_map
[20131218T17:44:29.185Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc||locking] update_leaf: vdi_location=df489463-b29f-41f0-a372-95ecca088905
[20131218T17:44:29.186Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc||nmutex] wait: reason=Finished op '"OpAttaching"'. Removing from cur
[20131218T17:44:29.186Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc||nmutex] About to broadcast
[20131218T17:44:29.186Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc||nmutex] Done
[20131218T17:44:29.186Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc||nmutex] wait: reason=Getting a copy of a VHD chain
[20131218T17:44:29.186Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc||lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-e906484b-7f75-4b2c-ba81-c966d9c7f7cc
[20131218T17:44:29.186Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc||lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-e906484b-7f75-4b2c-ba81-c966d9c7f7cc
[20131218T17:44:29.186Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc||lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-e906484b-7f75-4b2c-ba81-c966d9c7f7cc
[20131218T17:44:29.186Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc||vhdd] Response: {"result": {"sa_leaf_path": "\/dev\/mapper\/VG_XenStorage--1-VHD--e906484b--7f75--4b2c--ba81--c966d9c7f7cc", "sa_leaf_maxsize": 58720256, "sa_leaf_phys_size": 4311040, "sa_leaf_is_raw": false, "sa_writable": true, "sa_lvs": [["Mlvm", {"dmn_dm_name": "VG_XenStorage--1-VHD--e906484b--7f75--4b2c--ba81--c966d9c7f7cc", "dmn_mapping": {"m": [{"start": 0, "len": 114688, "map": ["Linear", {"device": ["Dereferenced", "Np3GjL-QHMs-pLNs-MZnG-jWQc-3jQ2-gGu2I1"], "offset": 45184}]}]}}]]}, "error": null, "id": 0}
[20131218T17:44:29.193Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 413 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:29.193Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:29.193Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.activate</methodName><params><param><value><struct><member><name>dbg</name><value>dbg</value></member><member><name>dp</name><value>df489463-b29f-41f0-a372-95ecca088905</value></member><member><name>sr</name><value>1</value></member><member><name>vdi</name><value>df489463-b29f-41f0-a372-95ecca088905</value></member></struct></value></param></params></methodCall>
[20131218T17:44:29.193Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|vhdsm] API call: VDI.activate sr=1 vdi=df489463-b29f-41f0-a372-95ecca088905
[20131218T17:44:29.193Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:29.193Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|nmutex] wait: reason=Adding to current_operations
[20131218T17:44:29.193Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|vhdSlave] Checking current ops
[20131218T17:44:29.193Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:29.193Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|nmutex] wait: reason=Checking whether the VDI is activated
[20131218T17:44:29.193Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:29.193Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|nmutex] wait: reason=Executing with operation '"OpActivating"'
[20131218T17:44:29.194Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:29.194Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|nmutex] wait: reason=Update id_map
[20131218T17:44:29.194Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|locking] update_leaf: vdi_location=df489463-b29f-41f0-a372-95ecca088905
[20131218T17:44:29.194Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|nmutex] wait: reason=Finished op '"OpActivating"'. Removing from cur
[20131218T17:44:29.194Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|nmutex] About to broadcast
[20131218T17:44:29.194Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|nmutex] Done
[20131218T17:44:29.194Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:29.194Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|nmutex] wait: reason=Adding to master_approved_ops
[20131218T17:44:29.194Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|vhdSlave] Checking current ops
[20131218T17:44:29.194Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:29.194Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|nmutex] wait: reason=Activating tapdisk
[20131218T17:44:29.195Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|tapdisk_listen] Registered to listen to /dev/shm/1_1_df489463-b29f-41f0-a372-95ecca088905.stats
[20131218T17:44:29.195Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|vhdSlave] Setting maxsize in shared page
[20131218T17:44:29.195Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|vhdSlave] Setting maxsize=58720256
[20131218T17:44:29.195Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:29.195Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|nmutex] wait: reason=Removing from master_approved_ops
[20131218T17:44:29.195Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|vhdSlave] Removing my current op
[20131218T17:44:29.195Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:29.195Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|nmutex] About to broadcast
[20131218T17:44:29.195Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|nmutex] Done
[20131218T17:44:29.195Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:29.195Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|nmutex] wait: reason=Removing from current_operations
[20131218T17:44:29.195Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|vhdSlave] Removing my current op
[20131218T17:44:29.195Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:29.195Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|nmutex] About to broadcast
[20131218T17:44:29.195Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|nmutex] Done
[20131218T17:44:29.196Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc|26cfe060-b603-4737-affb-6cc211700bae|vhdd] Response: (omitted)
[20131218T17:44:29.196Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 415 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:29.196Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:29.196Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.deactivate</methodName><params><param><value><struct><member><name>dbg</name><value>dbg</value></member><member><name>dp</name><value>df489463-b29f-41f0-a372-95ecca088905</value></member><member><name>sr</name><value>1</value></member><member><name>vdi</name><value>df489463-b29f-41f0-a372-95ecca088905</value></member></struct></value></param></params></methodCall>
[20131218T17:44:29.197Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|vhdsm] API call: VDI.deactivate sr=1 vdi=df489463-b29f-41f0-a372-95ecca088905
[20131218T17:44:29.197Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:29.197Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|nmutex] wait: reason=Adding to current_operations
[20131218T17:44:29.197Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|vhdSlave] Checking current ops
[20131218T17:44:29.197Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:29.197Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|nmutex] wait: reason=Deactivating
[20131218T17:44:29.197Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|tapdisk_listen] Unregistering 1/df489463-b29f-41f0-a372-95ecca088905
[20131218T17:44:29.197Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:29.197Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|nmutex] wait: reason=Executing with operation '"OpDeactivating"'
[20131218T17:44:29.198Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:29.198Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|nmutex] wait: reason=Update id_map
[20131218T17:44:29.198Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|locking] update_leaf: vdi_location=df489463-b29f-41f0-a372-95ecca088905
[20131218T17:44:29.198Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|nmutex] wait: reason=Finished op '"OpDeactivating"'. Removing from cur
[20131218T17:44:29.198Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|nmutex] About to broadcast
[20131218T17:44:29.198Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|nmutex] Done
[20131218T17:44:29.198Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:29.198Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|nmutex] wait: reason=Removing from current_operations
[20131218T17:44:29.198Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|vhdSlave] Removing my current op
[20131218T17:44:29.198Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:29.198Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|nmutex] About to broadcast
[20131218T17:44:29.198Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|nmutex] Done
[20131218T17:44:29.198Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|970f3870-4307-4321-a182-4ecead83b42a|vhdd] Response: (omitted)
[20131218T17:44:29.201Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc||http] Request { frame = false; method = POST; uri = /internal; query = [  ]; content_length = [ 155 ]; transfer encoding = ; version = 1.0; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = ; user_agent = xen-api-libs/1.0 }
[20131218T17:44:29.201Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc||vhdd] Internal handler
[20131218T17:44:29.201Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc||vhdd] Call={"method": "VDI.slave_activate", "params": [{"host_uuid": "2", "sr": "1", "vdi": "df489463-b29f-41f0-a372-95ecca088905", "is_reactivate": false}], "id": 4}
[20131218T17:44:29.201Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc||nmutex] wait: reason=Locked get leaf info
[20131218T17:44:29.201Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc||nmutex] wait: reason=Executing with operation '"OpActivating"'
[20131218T17:44:29.201Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc||nmutex] wait: reason=Locked get leaf info
[20131218T17:44:29.201Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc||nmutex] wait: reason=Update id_map
[20131218T17:44:29.201Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc||locking] update_leaf: vdi_location=df489463-b29f-41f0-a372-95ecca088905
[20131218T17:44:29.202Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc||nmutex] wait: reason=Finished op '"OpActivating"'. Removing from cur
[20131218T17:44:29.202Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc||nmutex] About to broadcast
[20131218T17:44:29.202Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc||nmutex] Done
[20131218T17:44:29.202Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc||vhdd] Response: {"result": null, "error": null, "id": 0}
[20131218T17:44:29.208Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|24 inet-rpc||http] Request { frame = false; method = POST; uri = /internal; query = [  ]; content_length = [ 133 ]; transfer encoding = ; version = 1.0; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = ; user_agent = xen-api-libs/1.0 }
[20131218T17:44:29.208Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|24 inet-rpc||vhdd] Internal handler
[20131218T17:44:29.208Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|24 inet-rpc||vhdd] Call={"method": "VDI.slave_deactivate", "params": [{"host_uuid": "2", "sr": "1", "vdi": "df489463-b29f-41f0-a372-95ecca088905"}], "id": 5}
[20131218T17:44:29.208Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|24 inet-rpc||nmutex] wait: reason=Locked get leaf info
[20131218T17:44:29.208Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|24 inet-rpc||nmutex] wait: reason=Executing with operation '"OpDeactivating"'
[20131218T17:44:29.208Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|24 inet-rpc||nmutex] wait: reason=Locked get leaf info
[20131218T17:44:29.208Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|24 inet-rpc||nmutex] wait: reason=Update id_map
[20131218T17:44:29.208Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|24 inet-rpc||locking] update_leaf: vdi_location=df489463-b29f-41f0-a372-95ecca088905
[20131218T17:44:29.208Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|24 inet-rpc||nmutex] wait: reason=Finished op '"OpDeactivating"'. Removing from cur
[20131218T17:44:29.209Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|24 inet-rpc||nmutex] About to broadcast
[20131218T17:44:29.209Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|24 inet-rpc||nmutex] Done
[20131218T17:44:29.209Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|24 inet-rpc||vhdd] Response: {"result": null, "error": null, "id": 0}
[20131218T17:44:29.211Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 411 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:29.211Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:29.211Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.detach</methodName><params><param><value><struct><member><name>dbg</name><value>dbg</value></member><member><name>dp</name><value>df489463-b29f-41f0-a372-95ecca088905</value></member><member><name>sr</name><value>1</value></member><member><name>vdi</name><value>df489463-b29f-41f0-a372-95ecca088905</value></member></struct></value></param></params></methodCall>
[20131218T17:44:29.211Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|vhdsm] API call: VDI.detach sr=1 vdi=df489463-b29f-41f0-a372-95ecca088905
[20131218T17:44:29.211Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:29.211Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|nmutex] wait: reason=Adding to current_operations
[20131218T17:44:29.211Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|vhdSlave] Checking current ops
[20131218T17:44:29.211Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:29.211Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|nmutex] wait: reason=Checking we're attached
[20131218T17:44:29.211Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|nmutex] wait: reason=Deactivating tapdisk if necessary
[20131218T17:44:29.212Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:29.212Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|nmutex] wait: reason=Executing with operation '"OpDetaching"'
[20131218T17:44:29.212Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:29.212Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|nmutex] wait: reason=Update id_map
[20131218T17:44:29.212Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|locking] update_leaf: vdi_location=df489463-b29f-41f0-a372-95ecca088905
[20131218T17:44:29.212Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|nmutex] wait: reason=Finished op '"OpDetaching"'. Removing from cur
[20131218T17:44:29.212Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|nmutex] About to broadcast
[20131218T17:44:29.212Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|nmutex] Done
[20131218T17:44:29.212Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:29.212Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|nmutex] wait: reason=Adding to master_approved_ops
[20131218T17:44:29.212Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|vhdSlave] Checking current ops
[20131218T17:44:29.212Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:29.212Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|nmutex] wait: reason=Reloading attach info
[20131218T17:44:29.212Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|host] Remove LV: refcount for dm=VG_XenStorage--1-VHD--e906484b--7f75--4b2c--ba81--c966d9c7f7cc is now 0
[20131218T17:44:29.212Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|host] Removing LV=VG_XenStorage--1-VHD--e906484b--7f75--4b2c--ba81--c966d9c7f7cc
[20131218T17:44:29.212Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|nmutex] wait: reason=Removing attach info
[20131218T17:44:29.213Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:29.213Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|nmutex] wait: reason=Removing from master_approved_ops
[20131218T17:44:29.213Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|vhdSlave] Removing my current op
[20131218T17:44:29.213Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:29.213Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|nmutex] About to broadcast
[20131218T17:44:29.213Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|nmutex] Done
[20131218T17:44:29.213Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:29.213Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|nmutex] wait: reason=Removing from current_operations
[20131218T17:44:29.213Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|vhdSlave] Removing my current op
[20131218T17:44:29.213Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:29.213Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|nmutex] About to broadcast
[20131218T17:44:29.213Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|nmutex] Done
[20131218T17:44:29.213Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|fe29efae-1f45-4820-92bf-76eeb5c3e961|vhdd] Response: (omitted)
[20131218T17:44:29.216Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||http] Request { frame = false; method = POST; uri = /internal; query = [  ]; content_length = [ 129 ]; transfer encoding = ; version = 1.0; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = ; user_agent = xen-api-libs/1.0 }
[20131218T17:44:29.217Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||vhdd] Internal handler
[20131218T17:44:29.217Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||vhdd] Call={"method": "VDI.slave_detach", "params": [{"host_uuid": "2", "sr": "1", "vdi": "df489463-b29f-41f0-a372-95ecca088905"}], "id": 6}
[20131218T17:44:29.217Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||nmutex] wait: reason=Locked get leaf info
[20131218T17:44:29.217Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||nmutex] wait: reason=Executing with operation '"OpDetaching"'
[20131218T17:44:29.217Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||nmutex] wait: reason=Locked get leaf info
[20131218T17:44:29.217Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||nmutex] wait: reason=Update id_map
[20131218T17:44:29.217Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||locking] update_leaf: vdi_location=df489463-b29f-41f0-a372-95ecca088905
[20131218T17:44:29.217Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||nmutex] wait: reason=Getting VHD uid='112325cf-1bbc-42c0-aba6-4c9dd3aac69f'
[20131218T17:44:29.217Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||vhdMaster_utils] Resizing VHD uid: 112325cf-1bbc-42c0-aba6-4c9dd3aac69f
[20131218T17:44:29.217Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-e906484b-7f75-4b2c-ba81-c966d9c7f7cc
[20131218T17:44:29.217Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||mlvm] Using dm_name=3d7e0e08-136c-4aa9-a6f7-079e19e8c0a9 (use_tmp=true)
[20131218T17:44:29.217Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||vhdutil] Dump size: overhead=4311040 phys_size=4311040 virtual_size=52428800 critical_size=56739840
[20131218T17:44:29.218Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||vhdutil] leaf_status: Some false reservation_type: Thin
[20131218T17:44:29.218Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-e906484b-7f75-4b2c-ba81-c966d9c7f7cc
[20131218T17:44:29.218Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||vhdMaster_utils] new_size=old_size=58720256. Not doing anything
[20131218T17:44:29.218Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||nmutex] wait: reason=Finished op '"OpDetaching"'. Removing from cur
[20131218T17:44:29.218Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||nmutex] About to broadcast
[20131218T17:44:29.218Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||nmutex] Done
[20131218T17:44:29.218Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||vhdd] Response: {"result": null, "error": null, "id": 0}
[20131218T17:44:29.228Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 422 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:29.228Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:29.228Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.deactivate</methodName><params><param><value><struct><member><name>dbg</name><value>detach_all</value></member><member><name>dp</name><value>df489463-b29f-41f0-a372-95ecca088905</value></member><member><name>sr</name><value>1</value></member><member><name>vdi</name><value>df489463-b29f-41f0-a372-95ecca088905</value></member></struct></value></param></params></methodCall>
[20131218T17:44:29.228Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|16f661c1-0ca2-49d2-a3c8-62dae8b9a830|vhdsm] API call: VDI.deactivate sr=1 vdi=df489463-b29f-41f0-a372-95ecca088905
[20131218T17:44:29.228Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|16f661c1-0ca2-49d2-a3c8-62dae8b9a830|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:29.228Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|16f661c1-0ca2-49d2-a3c8-62dae8b9a830|nmutex] wait: reason=Adding to current_operations
[20131218T17:44:29.228Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|16f661c1-0ca2-49d2-a3c8-62dae8b9a830|vhdSlave] Checking current ops
[20131218T17:44:29.228Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|16f661c1-0ca2-49d2-a3c8-62dae8b9a830|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:29.228Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|16f661c1-0ca2-49d2-a3c8-62dae8b9a830|nmutex] wait: reason=Deactivating
[20131218T17:44:29.228Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|16f661c1-0ca2-49d2-a3c8-62dae8b9a830|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:29.228Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|16f661c1-0ca2-49d2-a3c8-62dae8b9a830|nmutex] wait: reason=Removing from current_operations
[20131218T17:44:29.228Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|16f661c1-0ca2-49d2-a3c8-62dae8b9a830|vhdSlave] Removing my current op
[20131218T17:44:29.228Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|16f661c1-0ca2-49d2-a3c8-62dae8b9a830|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:29.229Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|16f661c1-0ca2-49d2-a3c8-62dae8b9a830|nmutex] About to broadcast
[20131218T17:44:29.229Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|16f661c1-0ca2-49d2-a3c8-62dae8b9a830|nmutex] Done
[20131218T17:44:29.229Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|16f661c1-0ca2-49d2-a3c8-62dae8b9a830|vhdd] Response: (omitted)
[20131218T17:44:29.230Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 418 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:29.230Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:29.230Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.detach</methodName><params><param><value><struct><member><name>dbg</name><value>detach_all</value></member><member><name>dp</name><value>df489463-b29f-41f0-a372-95ecca088905</value></member><member><name>sr</name><value>1</value></member><member><name>vdi</name><value>df489463-b29f-41f0-a372-95ecca088905</value></member></struct></value></param></params></methodCall>
[20131218T17:44:29.230Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc|33dbb5cd-dc44-4486-afe0-92045b9374e3|vhdsm] API call: VDI.detach sr=1 vdi=df489463-b29f-41f0-a372-95ecca088905
[20131218T17:44:29.231Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc|33dbb5cd-dc44-4486-afe0-92045b9374e3|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:29.231Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc|33dbb5cd-dc44-4486-afe0-92045b9374e3|nmutex] wait: reason=Adding to current_operations
[20131218T17:44:29.231Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc|33dbb5cd-dc44-4486-afe0-92045b9374e3|vhdSlave] Checking current ops
[20131218T17:44:29.231Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc|33dbb5cd-dc44-4486-afe0-92045b9374e3|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:29.231Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc|33dbb5cd-dc44-4486-afe0-92045b9374e3|nmutex] wait: reason=Checking we're attached
[20131218T17:44:29.231Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc|33dbb5cd-dc44-4486-afe0-92045b9374e3|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:29.231Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc|33dbb5cd-dc44-4486-afe0-92045b9374e3|nmutex] wait: reason=Removing from current_operations
[20131218T17:44:29.231Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc|33dbb5cd-dc44-4486-afe0-92045b9374e3|vhdSlave] Removing my current op
[20131218T17:44:29.231Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc|33dbb5cd-dc44-4486-afe0-92045b9374e3|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:29.231Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc|33dbb5cd-dc44-4486-afe0-92045b9374e3|nmutex] About to broadcast
[20131218T17:44:29.231Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc|33dbb5cd-dc44-4486-afe0-92045b9374e3|nmutex] Done
[20131218T17:44:29.231Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc|33dbb5cd-dc44-4486-afe0-92045b9374e3|vhdd] Response: (omitted)
[20131218T17:44:29.232Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 250 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:29.232Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:29.233Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>SR.detach</methodName><params><param><value><struct><member><name>dbg</name><value>detach_all</value></member><member><name>sr</name><value>1</value></member></struct></value></param></params></methodCall>
[20131218T17:44:29.233Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc|e0ca2da3-bfc9-4bcf-aaee-b8b37ff5bd07|lvmabs] operating on vg: VG_XenStorage-1 lv: host_attachments
[20131218T17:44:29.233Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc|e0ca2da3-bfc9-4bcf-aaee-b8b37ff5bd07|host] attach_lv: Got the mutex
[20131218T17:44:29.233Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc|e0ca2da3-bfc9-4bcf-aaee-b8b37ff5bd07|host] LV VG_XenStorage--1-host_attachments not attached: attaching. refcount now 1
[20131218T17:44:29.233Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc|e0ca2da3-bfc9-4bcf-aaee-b8b37ff5bd07|mlvm] Using dm_name=VG_XenStorage--1-host_attachments (use_tmp=false)
[20131218T17:44:29.233Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc|e0ca2da3-bfc9-4bcf-aaee-b8b37ff5bd07|host] attach_lv: released the mutex
[20131218T17:44:29.233Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc|e0ca2da3-bfc9-4bcf-aaee-b8b37ff5bd07|host] Remove LV: refcount for dm=VG_XenStorage--1-host_attachments is now 0
[20131218T17:44:29.234Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc|e0ca2da3-bfc9-4bcf-aaee-b8b37ff5bd07|host] Removing LV=VG_XenStorage--1-host_attachments
[20131218T17:44:29.234Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc|e0ca2da3-bfc9-4bcf-aaee-b8b37ff5bd07|mlvm] write_label_and_pv_header:
PV header:
pvh_id: Np3GjL-QHMs-pLNs-MZnG-jWQc-3jQ2-gGu2I1
pvh_device_size: 1099511627776
pvh_areas1: {offset=10551296,size=0}
pvh_areas2: {offset=4096,size=10547200}

[20131218T17:44:29.235Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc|e0ca2da3-bfc9-4bcf-aaee-b8b37ff5bd07|mlvm] Writing MDA header
[20131218T17:44:29.235Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc|e0ca2da3-bfc9-4bcf-aaee-b8b37ff5bd07|mlvm] Writing: checksum: 640328066
magic:  LVM2 x[5A%r0N*>
version: 1
start: 4096
size: 10485760
raw_locns:[{offset:2048,size:1455,checksum:-442044974,filler:0}]

[20131218T17:44:29.235Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc|e0ca2da3-bfc9-4bcf-aaee-b8b37ff5bd07|host] remove_pv_id_info: Got mutex
[20131218T17:44:29.235Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc|e0ca2da3-bfc9-4bcf-aaee-b8b37ff5bd07|host] remove_pv_id_info: Released mutex
[20131218T17:44:29.235Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc|e0ca2da3-bfc9-4bcf-aaee-b8b37ff5bd07|vhdd] Response: (omitted)
[20131218T17:44:29.236Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc||http] Request { frame = false; method = POST; uri = /internal; query = [  ]; content_length = [ 67 ]; transfer encoding = ; version = 1.0; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = ; user_agent = xen-api-libs/1.0 }
[20131218T17:44:29.236Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc||vhdd] Internal handler
[20131218T17:44:29.237Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc||vhdd] Call={"method": "Debug.die", "params": [{"restart": false}], "id": 2439}
[20131218T17:44:29.237Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc||vhdsm] Got instruction to die with restart=false
[20131218T17:44:29.239Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|0||watchdog] received exit code 0. Not restarting.
