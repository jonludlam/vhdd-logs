[20131218T17:44:21.706Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|0||watchdog] (Re)starting vhdd...
[20131218T17:44:21.707Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|0||watchdog] Child vhdd is: 26462
[20131218T17:44:21.707Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|0||http] Establishing inet domain server
[20131218T17:44:21.709Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|0||attachments] Ignoring ENOENT while reading attachments file
[20131218T17:44:21.710Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|9 inet-rpc||http] Request { frame = false; method = POST; uri = /internal; query = [  ]; content_length = [ 57 ]; transfer encoding = ; version = 1.0; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = ; user_agent = xen-api-libs/1.0 }
[20131218T17:44:21.710Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|9 inet-rpc||vhdd] Internal handler
[20131218T17:44:21.710Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|9 inet-rpc||vhdd] Call={"method": "Debug.get_pid", "params": [null], "id": 1148}
[20131218T17:44:21.710Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|9 inet-rpc||vhdd] Response: {"result": 26462, "error": null, "id": 0}
[20131218T17:44:21.711Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|12 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 204 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:21.711Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|12 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:21.712Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|12 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>SR.list</methodName><params><param><value><struct><member><name>dbg</name><value>wait_for_start</value></member></struct></value></param></params></methodCall>
[20131218T17:44:21.712Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|12 inet-rpc|e907f008-83ce-4e68-9c39-7d54f4af44eb|vhdd] Response: (omitted)
[20131218T17:44:21.713Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 574 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:21.714Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:21.714Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>SR.create</methodName><params><param><value><struct><member><name>dbg</name><value>create_and_attach</value></member><member><name>sr</name><value>1</value></member><member><name>device_config</name><value><struct><member><name>SRmaster</name><value>true</value></member><member><name>device</name><value>/dev/dummy</value></member><member><name>reservation_mode</name><value>thin</value></member></struct></value></member><member><name>physical_size</name><value>0</value></member></struct></value></param></params></methodCall>
[20131218T17:44:21.714Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc|ba8b8063-f293-4f0a-bb29-be22c350fdb0|mlvm] write_label_and_pv_header:
PV header:
pvh_id: HuQ48U-d2tF-atyS-Sxpy-7CRJ-kZBL-5ZS8AZ
pvh_device_size: 1099511627776
pvh_areas1: {offset=10551296,size=0}
pvh_areas2: {offset=4096,size=10547200}

[20131218T17:44:21.743Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc|ba8b8063-f293-4f0a-bb29-be22c350fdb0|mlvm] Writing MDA header
[20131218T17:44:21.766Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc|ba8b8063-f293-4f0a-bb29-be22c350fdb0|mlvm] Writing: checksum: 0
magic:  LVM2 x[5A%r0N*>
version: 1
start: 4096
size: 10485760
raw_locns:[{offset:512,size:0,checksum:0,filler:0}]

[20131218T17:44:21.769Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc|ba8b8063-f293-4f0a-bb29-be22c350fdb0|mlvm] PVs created
[20131218T17:44:21.769Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc|ba8b8063-f293-4f0a-bb29-be22c350fdb0|mlvm] write_label_and_pv_header:
PV header:
pvh_id: HuQ48U-d2tF-atyS-Sxpy-7CRJ-kZBL-5ZS8AZ
pvh_device_size: 1099511627776
pvh_areas1: {offset=10551296,size=0}
pvh_areas2: {offset=4096,size=10547200}

[20131218T17:44:21.773Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc|ba8b8063-f293-4f0a-bb29-be22c350fdb0|mlvm] Writing MDA header
[20131218T17:44:21.773Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc|ba8b8063-f293-4f0a-bb29-be22c350fdb0|mlvm] Writing: checksum: 0
magic:  LVM2 x[5A%r0N*>
version: 1
start: 4096
size: 10485760
raw_locns:[{offset:512,size:511,checksum:1489032055,filler:0}]

[20131218T17:44:21.773Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc|ba8b8063-f293-4f0a-bb29-be22c350fdb0|mlvm] VG created
[20131218T17:44:21.774Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|13 inet-rpc|ba8b8063-f293-4f0a-bb29-be22c350fdb0|vhdd] Response: (omitted)
[20131218T17:44:21.779Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 515 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:21.779Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:21.779Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>SR.attach</methodName><params><param><value><struct><member><name>dbg</name><value>create_and_attach</value></member><member><name>sr</name><value>1</value></member><member><name>device_config</name><value><struct><member><name>SRmaster</name><value>true</value></member><member><name>device</name><value>/dev/dummy</value></member><member><name>reservation_mode</name><value>thin</value></member></struct></value></member></struct></value></param></params></methodCall>
[20131218T17:44:21.779Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|lvmabs] init_lvm: Loading Vg from devices list: [/dev/dummy]
[20131218T17:44:21.779Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] Vg.load
[20131218T17:44:21.779Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] Label found: 
Label header:
id: LABELONE
sector: 1
crc: 1338400369
offset: 32
ty: LVM2 001

PV Header:
pvh_id: HuQ48U-d2tF-atyS-Sxpy-7CRJ-kZBL-5ZS8AZ
pvh_device_size: 1099511627776
pvh_areas1: {offset=10551296,size=0}
pvh_areas2: {offset=4096,size=10547200}



[20131218T17:44:21.780Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|lvmabs] init_lvm: Vg loaded:
[20131218T17:44:21.780Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|lvmabs] VG_XenStorage-1 {
id = "b3E9w8-05mx-4PfN-i1hL-8z7L-wkjV-DpW9Ia"
seqno = 1
status = ["READ", "WRITE"]
extent_size = 8192
max_lv = 0
max_pv = 0

physical_volumes {

pv0 {
id = "HuQ48U-d2tF-atyS-Sxpy-7CRJ-kZBL-5ZS8AZ"
device = "/dev/dummy"

status = ["ALLOCATABLE"]
dev_size = 2147483648
pe_start = 20608
pe_count = 262141
}
}

logical_volumes {
}
}
# Generated by MLVM version 0.1: 

contents = "Text Format Volume Group"
version = 1

description = ""

creation_host = "<need uname!>"
creation_time = 1387388661


[20131218T17:44:21.780Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] write_label_and_pv_header:
PV header:
pvh_id: HuQ48U-d2tF-atyS-Sxpy-7CRJ-kZBL-5ZS8AZ
pvh_device_size: 1099511627776
pvh_areas1: {offset=10551296,size=0}
pvh_areas2: {offset=4096,size=10547200}

[20131218T17:44:21.781Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] Writing MDA header
[20131218T17:44:21.781Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] Writing: checksum: -1373777123
magic:  LVM2 x[5A%r0N*>
version: 1
start: 4096
size: 10485760
raw_locns:[{offset:1024,size:738,checksum:-476078592,filler:0}]

[20131218T17:44:21.781Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|lvmabs] init_lvm: Redo log initialized:
[20131218T17:44:21.781Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|lvmabs] VG_XenStorage-1 {
id = "b3E9w8-05mx-4PfN-i1hL-8z7L-wkjV-DpW9Ia"
seqno = 2
status = ["READ", "WRITE"]
extent_size = 8192
max_lv = 0
max_pv = 0

physical_volumes {

pv0 {
id = "HuQ48U-d2tF-atyS-Sxpy-7CRJ-kZBL-5ZS8AZ"
device = "/dev/dummy"

status = ["ALLOCATABLE"]
dev_size = 2147483648
pe_start = 20608
pe_count = 262141
}
}

logical_volumes {

mlvm_redo_log {
id = "M7Awjd-Guql-LuwU-ceaR-tkQt-DgZE-j3ly5b"
status = ["READ", "VISIBLE"]
segment_count = 1

segment1 {
start_extent = 0
extent_count = 1

type = "striped"
stripe_count = 1	#linear

stripes = [
"pv0", 0
]
}
}
}
}
# Generated by MLVM version 0.1: 

contents = "Text Format Volume Group"
version = 1

description = ""

creation_host = "<need uname!>"
creation_time = 1387388661


[20131218T17:44:21.781Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] add_pv_id_info: Got mutex
[20131218T17:44:21.781Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] add_pv_id_info: Released mutex
[20131218T17:44:21.781Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|vhdSlave] VhdSlave.SR.attach
[20131218T17:44:21.781Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|tapdisk] Tapdisk.scan
[20131218T17:44:21.781Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|tapdisk] parse_tapdev_link: ..
[20131218T17:44:21.781Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|tapdisk] parse_tapdev_link: .
[20131218T17:44:21.782Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|attachments] attach as slave: 1
[20131218T17:44:21.782Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|attachments] Ignoring ENOENT while reading attachments file
[20131218T17:44:21.782Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|vhdsm] mode=Master
[20131218T17:44:21.782Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|vhdmaster] m_rolling_upgrade=false
[20131218T17:44:21.782Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|lvmabs] init_lvm: Loading Vg from devices list: [/dev/dummy]
[20131218T17:44:21.782Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] Vg.load
[20131218T17:44:21.782Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] Label found: 
Label header:
id: LABELONE
sector: 1
crc: 1338400369
offset: 32
ty: LVM2 001

PV Header:
pvh_id: HuQ48U-d2tF-atyS-Sxpy-7CRJ-kZBL-5ZS8AZ
pvh_device_size: 1099511627776
pvh_areas1: {offset=10551296,size=0}
pvh_areas2: {offset=4096,size=10547200}



[20131218T17:44:21.783Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] Allocations for lv mlvm_redo_log:
(pv0: [0,1])

[20131218T17:44:21.783Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] Redo.read
[20131218T17:44:21.783Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] start_ofs: 12 end_ofs: 12 size: 0
[20131218T17:44:21.783Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] Reading from pos: 0
[20131218T17:44:21.783Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] Redo.read finished
[20131218T17:44:21.783Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|lvmabs] init_lvm: Vg loaded:
[20131218T17:44:21.783Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|lvmabs] VG_XenStorage-1 {
id = "b3E9w8-05mx-4PfN-i1hL-8z7L-wkjV-DpW9Ia"
seqno = 2
status = ["READ", "WRITE"]
extent_size = 8192
max_lv = 0
max_pv = 0

physical_volumes {

pv0 {
id = "HuQ48U-d2tF-atyS-Sxpy-7CRJ-kZBL-5ZS8AZ"
device = "/dev/dummy"

status = ["ALLOCATABLE"]
dev_size = 2147483648
pe_start = 20608
pe_count = 262141
}
}

logical_volumes {

mlvm_redo_log {
id = "M7Awjd-Guql-LuwU-ceaR-tkQt-DgZE-j3ly5b"
status = ["READ", "VISIBLE"]
segment_count = 1

segment1 {
start_extent = 0
extent_count = 1

type = "striped"
stripe_count = 1	#linear

stripes = [
"pv0", 0
]
}
}
}
}
# Generated by MLVM version 0.1: 

contents = "Text Format Volume Group"
version = 1

description = ""

creation_host = "<need uname!>"
creation_time = 1387388661


[20131218T17:44:21.783Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|lvmabs] init_lvm: Redo log initialized:
[20131218T17:44:21.783Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|lvmabs] VG_XenStorage-1 {
id = "b3E9w8-05mx-4PfN-i1hL-8z7L-wkjV-DpW9Ia"
seqno = 2
status = ["READ", "WRITE"]
extent_size = 8192
max_lv = 0
max_pv = 0

physical_volumes {

pv0 {
id = "HuQ48U-d2tF-atyS-Sxpy-7CRJ-kZBL-5ZS8AZ"
device = "/dev/dummy"

status = ["ALLOCATABLE"]
dev_size = 2147483648
pe_start = 20608
pe_count = 262141
}
}

logical_volumes {

mlvm_redo_log {
id = "M7Awjd-Guql-LuwU-ceaR-tkQt-DgZE-j3ly5b"
status = ["READ", "VISIBLE"]
segment_count = 1

segment1 {
start_extent = 0
extent_count = 1

type = "striped"
stripe_count = 1	#linear

stripes = [
"pv0", 0
]
}
}
}
}
# Generated by MLVM version 0.1: 

contents = "Text Format Volume Group"
version = 1

description = ""

creation_host = "<need uname!>"
creation_time = 1387388661


[20131218T17:44:21.783Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|vhdmaster] container initialised
[20131218T17:44:21.783Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|scan] scan
[20131218T17:44:21.784Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|lvmabs] operating on vg: VG_XenStorage-1 lv: mlvm_redo_log
[20131218T17:44:21.784Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|lvmabs] operating on vg: VG_XenStorage-1 lv: mlvm_redo_log
[20131218T17:44:21.784Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] Using dm_name=0529a287-98f9-4b4c-b95b-238afb93aa0a (use_tmp=true)
[20131218T17:44:21.784Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|scan] Reading VHD: /tmp/dummytest/1/dev/mapper/0529a287-98f9-4b4c-b95b-238afb93aa0a
[20131218T17:44:21.784Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] LVM REDO: 000000000113„•¦¾   ]      -   $ B 0host_attachments 	&T7GBLY-MRpP-fGoA-oeTl-OZEB-rhN0-AvVumK  #pv0 _j        _j        @
[20131218T17:44:21.785Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|lvmabs] operating on vg: VG_XenStorage-1 lv: host_attachments
[20131218T17:44:21.785Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] Using dm_name=78fbef5d-c107-4109-94a0-d875d0fe87dc (use_tmp=true)
[20131218T17:44:21.785Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|lvmabs] operating on vg: VG_XenStorage-1 lv: host_attachments
[20131218T17:44:21.785Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] attach_lv: Got the mutex
[20131218T17:44:21.785Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] LV VG_XenStorage--1-host_attachments not attached: attaching. refcount now 1
[20131218T17:44:21.785Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] Using dm_name=VG_XenStorage--1-host_attachments (use_tmp=false)
[20131218T17:44:21.785Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] attach_lv: released the mutex
[20131218T17:44:21.785Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] Remove LV: refcount for dm=VG_XenStorage--1-host_attachments is now 0
[20131218T17:44:21.785Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] Removing LV=VG_XenStorage--1-host_attachments
[20131218T17:44:21.786Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] LVM REDO: 000000000115„•¦¾   _      -   $ C 2id_to_leaf_mapping 	&gtUzQY-9JRx-1ugW-VoZ5-GHRz-vOIn-pBV7sd  #pv0 _j        _j        @
[20131218T17:44:21.786Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|lvmabs] operating on vg: VG_XenStorage-1 lv: id_to_leaf_mapping
[20131218T17:44:21.786Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] Using dm_name=510556d5-4da8-4858-a729-2675c5bfd48b (use_tmp=true)
[20131218T17:44:21.787Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|lvmabs] operating on vg: VG_XenStorage-1 lv: id_to_leaf_mapping
[20131218T17:44:21.787Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] attach_lv: Got the mutex
[20131218T17:44:21.787Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] LV VG_XenStorage--1-id_to_leaf_mapping not attached: attaching. refcount now 1
[20131218T17:44:21.787Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] Using dm_name=VG_XenStorage--1-id_to_leaf_mapping (use_tmp=false)
[20131218T17:44:21.787Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] attach_lv: released the mutex
[20131218T17:44:21.787Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] Remove LV: refcount for dm=VG_XenStorage--1-id_to_leaf_mapping is now 0
[20131218T17:44:21.787Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] Removing LV=VG_XenStorage--1-id_to_leaf_mapping
[20131218T17:44:21.787Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|vhdmaster] Selected provisioning policy: Thin
[20131218T17:44:21.787Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|lvmabs] operating on vg: VG_XenStorage-1 lv: host_attachments
[20131218T17:44:21.788Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] attach_lv: Got the mutex
[20131218T17:44:21.788Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] LV VG_XenStorage--1-host_attachments not attached: attaching. refcount now 1
[20131218T17:44:21.788Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] Using dm_name=VG_XenStorage--1-host_attachments (use_tmp=false)
[20131218T17:44:21.788Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] attach_lv: released the mutex
[20131218T17:44:21.788Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] Remove LV: refcount for dm=VG_XenStorage--1-host_attachments is now 0
[20131218T17:44:21.788Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] Removing LV=VG_XenStorage--1-host_attachments
[20131218T17:44:21.788Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|vhdmaster] Recovering any slaves
[20131218T17:44:21.788Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|nmutex] wait: reason=Retrieving the hashtbl of attached hosts
[20131218T17:44:21.788Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|vhdmaster] About to get_localhost()
[20131218T17:44:21.788Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|vhdmaster] Creating the attach_part_two thread
[20131218T17:44:21.789Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|vhdmaster] About to iterate over attached slaves
[20131218T17:44:21.790Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|vhdSlave] Registering with master
[20131218T17:44:21.790Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|nmutex] wait: reason=Finding all attached/activated VDIs
[20131218T17:44:21.790Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|vhdmaster] Attach from host: 1, ip: 127.0.0.1
[20131218T17:44:21.790Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|slave_sr_attachments] Slave SR attach
[20131218T17:44:21.790Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|nmutex] wait: reason=Adding host to the attached_hosts
[20131218T17:44:21.790Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|lvmabs] operating on vg: VG_XenStorage-1 lv: host_attachments
[20131218T17:44:21.790Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] attach_lv: Got the mutex
[20131218T17:44:21.790Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] LV VG_XenStorage--1-host_attachments not attached: attaching. refcount now 1
[20131218T17:44:21.790Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] Using dm_name=VG_XenStorage--1-host_attachments (use_tmp=false)
[20131218T17:44:21.790Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] attach_lv: released the mutex
[20131218T17:44:21.791Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] Remove LV: refcount for dm=VG_XenStorage--1-host_attachments is now 0
[20131218T17:44:21.791Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] Removing LV=VG_XenStorage--1-host_attachments
[20131218T17:44:21.791Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|nmutex] wait: reason=Resyncing VDI attachments/activations
[20131218T17:44:21.791Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|vhdSlave] Registration functions finished. Setting s_ready=true
[20131218T17:44:21.791Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|vhdsm] s_ready for the slave is: true
[20131218T17:44:21.791Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|lvmabs] operating on vg: VG_XenStorage-1 lv: host_attachments
[20131218T17:44:21.791Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] attach_lv: Got the mutex
[20131218T17:44:21.791Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] LV VG_XenStorage--1-host_attachments not attached: attaching. refcount now 1
[20131218T17:44:21.791Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|mlvm] Using dm_name=VG_XenStorage--1-host_attachments (use_tmp=false)
[20131218T17:44:21.791Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] attach_lv: released the mutex
[20131218T17:44:21.791Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] Remove LV: refcount for dm=VG_XenStorage--1-host_attachments is now 0
[20131218T17:44:21.791Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|host] Removing LV=VG_XenStorage--1-host_attachments
[20131218T17:44:21.792Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|14 inet-rpc|4e3e39a3-665b-481d-84dc-4e44f1a469e5|vhdd] Response: (omitted)
[20131218T17:44:21.789Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|15||vhdmaster] attach_part_two thread created
[20131218T17:44:21.792Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|15||nmutex] wait: reason=Checking whether resync is required
[20131218T17:44:21.792Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|15||vhdmaster] Attach part two
[20131218T17:44:21.792Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|15||nmutex] wait: reason=Getting all the leaf infos
[20131218T17:44:21.792Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|15||vhdmaster] Resolving map inconsistencies
[20131218T17:44:21.792Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|15||vhdmaster] Resolved
[20131218T17:44:21.792Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|15||nmutex] wait: reason=setting coalesce_in_progress flag
[20131218T17:44:21.793Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|15||nmutex] wait: reason=Unsetting coalesce_in_progress flag
[20131218T17:44:21.793Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|15||nmutex] About to broadcast
[20131218T17:44:21.793Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|15||nmutex] Done
[20131218T17:44:21.807Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|16 inet-rpc||http] Request { frame = false; method = POST; uri = /internal; query = [  ]; content_length = [ 55 ]; transfer encoding = ; version = 1.0; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = ; user_agent = xen-api-libs/1.0 }
[20131218T17:44:21.807Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|16 inet-rpc||vhdd] Internal handler
[20131218T17:44:21.807Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|16 inet-rpc||vhdd] Call={"method": "SR.mode", "params": [{"sr": "1"}], "id": 1}
[20131218T17:44:21.807Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|16 inet-rpc||vhdd] Response: {"result": "Master", "error": null, "id": 0}
[20131218T17:44:21.810Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||http] Request { frame = false; method = POST; uri = /internal; query = [  ]; content_length = [ 137 ]; transfer encoding = ; version = 1.0; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = ; user_agent = xen-api-libs/1.0 }
[20131218T17:44:21.810Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||vhdd] Internal handler
[20131218T17:44:21.810Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||vhdd] Call={"method": "SR.slave_attach", "params": [{"sr": "1", "host": {"h_uuid": "2", "h_ip": "127.0.0.1", "h_port": 4095}, "vdis": {}}], "id": 2}
[20131218T17:44:21.810Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||vhdmaster] Attach from host: 2, ip: 127.0.0.1
[20131218T17:44:21.810Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||slave_sr_attachments] Slave SR attach
[20131218T17:44:21.810Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||nmutex] wait: reason=Adding host to the attached_hosts
[20131218T17:44:21.810Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||lvmabs] operating on vg: VG_XenStorage-1 lv: host_attachments
[20131218T17:44:21.810Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||host] attach_lv: Got the mutex
[20131218T17:44:21.810Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||host] LV VG_XenStorage--1-host_attachments not attached: attaching. refcount now 1
[20131218T17:44:21.810Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||mlvm] Using dm_name=VG_XenStorage--1-host_attachments (use_tmp=false)
[20131218T17:44:21.811Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||host] attach_lv: released the mutex
[20131218T17:44:21.811Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||host] Remove LV: refcount for dm=VG_XenStorage--1-host_attachments is now 0
[20131218T17:44:21.811Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||host] Removing LV=VG_XenStorage--1-host_attachments
[20131218T17:44:21.811Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||nmutex] wait: reason=Resyncing VDI attachments/activations
[20131218T17:44:21.811Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|17 inet-rpc||vhdd] Response: {"result": "OK", "error": null, "id": 0}
[20131218T17:44:21.814Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 1207 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:21.814Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:21.814Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.create</methodName><params><param><value><struct><member><name>dbg</name><value>create_vdi</value></member><member><name>sr</name><value>1</value></member><member><name>vdi_info</name><value><struct><member><name>vdi</name><value>vdi</value></member><member><name>content_id</name><value></value></member><member><name>name_label</name><value>ftest_vdi</value></member><member><name>name_description</name><value></value></member><member><name>ty</name><value>user</value></member><member><name>metadata_of_pool</name><value></value></member><member><name>is_a_snapshot</name><value><boolean>0</boolean></value></member><member><name>snapshot_time</name><value></value></member><member><name>snapshot_of</name><value></value></member><member><name>read_only</name><value><boolean>0</boolean></value></member><member><name>virtual_size</name><value>52428800</value></member><member><name>physical_utilisation</name><value>0</value></member><member><name>persistent</name><value><boolean>1</boolean></value></member><member><name>sm_config</name><value><struct></struct></value></member></struct></value></member></struct></value></param></params></methodCall>
[20131218T17:44:21.814Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|vhdsm] API call: VDI.create sr=1 size=52428800 sm_config=[]
[20131218T17:44:21.814Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|vhdutil] Dump size: overhead=4312576 phys_size=4312576 virtual_size=52428800 critical_size=109170176
[20131218T17:44:21.815Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|vhdutil] leaf_status: Some false reservation_type: Thin
[20131218T17:44:21.815Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:21.815Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|mlvm] LVM REDO: 000000000138„•¦¾   v      3   ' D 	(VHD-3b7ce781-fa29-42a4-ab34-e8655251f549 	&NmmsaE-kOrw-F9c8-ERXw-4nog-7cEn-ThyMiK  #pv0 _j        _j        @
[20131218T17:44:21.815Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:21.815Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|host] attach_lv: Got the mutex
[20131218T17:44:21.815Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|host] LV VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 not attached: attaching. refcount now 1
[20131218T17:44:21.815Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|mlvm] Using dm_name=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 (use_tmp=false)
[20131218T17:44:21.816Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|host] attach_lv: released the mutex
[20131218T17:44:21.857Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|vhdutil] query_size_vhd: Querying size of VHD 26d5a422-bac7-4d28-aaaa-2c56d610f77f
[20131218T17:44:21.857Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|vhdutil] query_size_vhd: get_phys_size returned 4311040
[20131218T17:44:21.857Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|vhdutil] query_size_vhd: first_allocated_block=None
[20131218T17:44:21.857Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|vhdutil] query_size_vhd: virtual_size=52428800
[20131218T17:44:21.857Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|nmutex] wait: reason=Adding VHD uid='26d5a422-bac7-4d28-aaaa-2c56d610f77f'
[20131218T17:44:21.857Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|host] Remove LV: refcount for dm=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 is now 0
[20131218T17:44:21.858Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|host] Removing LV=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549
[20131218T17:44:21.858Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|nmutex] wait: reason=Adding a new ID to the mapping (04385b43-bc7b-4ca5-a23a-361c99f6189c->PVhd '26d5a422-bac7-4d28-aaaa-2c56d610f77f')
[20131218T17:44:21.858Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|lvmabs] operating on vg: VG_XenStorage-1 lv: id_to_leaf_mapping
[20131218T17:44:21.858Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|host] attach_lv: Got the mutex
[20131218T17:44:21.858Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|host] LV VG_XenStorage--1-id_to_leaf_mapping not attached: attaching. refcount now 1
[20131218T17:44:21.858Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|mlvm] Using dm_name=VG_XenStorage--1-id_to_leaf_mapping (use_tmp=false)
[20131218T17:44:21.858Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|host] attach_lv: released the mutex
[20131218T17:44:21.858Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|host] Remove LV: refcount for dm=VG_XenStorage--1-id_to_leaf_mapping is now 0
[20131218T17:44:21.858Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|host] Removing LV=VG_XenStorage--1-id_to_leaf_mapping
[20131218T17:44:21.859Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|18 inet-rpc|f148ea0e-b6c2-4a81-8d8a-05c602fc5591|vhdd] Response: (omitted)
[20131218T17:44:21.860Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 486 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:21.860Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:21.860Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.attach</methodName><params><param><value><struct><member><name>dbg</name><value>dbg</value></member><member><name>dp</name><value>04385b43-bc7b-4ca5-a23a-361c99f6189c</value></member><member><name>sr</name><value>1</value></member><member><name>vdi</name><value>04385b43-bc7b-4ca5-a23a-361c99f6189c</value></member><member><name>read_write</name><value><boolean>1</boolean></value></member></struct></value></param></params></methodCall>
[20131218T17:44:21.860Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdsm] API call: VDI.attach sr=1 vdi=04385b43-bc7b-4ca5-a23a-361c99f6189c writable=true
[20131218T17:44:21.860Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:21.860Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|nmutex] wait: reason=Adding to current_operations
[20131218T17:44:21.860Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdSlave] Checking current ops
[20131218T17:44:21.861Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:21.861Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|nmutex] wait: reason=Finding whether we're already attached
[20131218T17:44:21.861Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|nmutex] wait: reason=Retrieving the hashtbl of attached hosts
[20131218T17:44:21.861Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdmaster] Got to the slave_attach function call
[20131218T17:44:21.861Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:21.861Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|nmutex] wait: reason=Executing with operation '"OpAttaching"'
[20131218T17:44:21.861Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:21.861Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|nmutex] wait: reason=Getting VHD uid='26d5a422-bac7-4d28-aaaa-2c56d610f77f'
[20131218T17:44:21.861Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdMaster_utils] Resizing VHD uid: 26d5a422-bac7-4d28-aaaa-2c56d610f77f
[20131218T17:44:21.861Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:21.862Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|mlvm] Using dm_name=82ea833e-0af2-4811-af56-9bfc5a044ddf (use_tmp=true)
[20131218T17:44:21.862Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdutil] Dump size: overhead=4311040 phys_size=4311040 virtual_size=52428800 critical_size=56739840
[20131218T17:44:21.862Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdutil] leaf_status: Some true reservation_type: Thin
[20131218T17:44:21.862Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:21.862Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdMaster_utils] new_size=old_size=58720256. Not doing anything
[20131218T17:44:21.862Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|nmutex] wait: reason=Update id_map
[20131218T17:44:21.862Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|locking] update_leaf: vdi_location=04385b43-bc7b-4ca5-a23a-361c99f6189c
[20131218T17:44:21.863Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|nmutex] wait: reason=Finished op '"OpAttaching"'. Removing from cur
[20131218T17:44:21.863Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|nmutex] About to broadcast
[20131218T17:44:21.863Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|nmutex] Done
[20131218T17:44:21.863Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|nmutex] wait: reason=Getting a copy of a VHD chain
[20131218T17:44:21.863Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:21.863Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:21.863Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:21.863Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdSlave] Got response: leaf=/tmp/dummytest/1//dev/mapper/VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549
[20131218T17:44:21.863Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:21.863Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|nmutex] wait: reason=Adding to master_approved_ops
[20131218T17:44:21.863Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdSlave] Checking current ops
[20131218T17:44:21.863Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:21.864Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdSlave] LV name: VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549
[20131218T17:44:21.864Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|host] attach_lv: Got the mutex
[20131218T17:44:21.864Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|host] LV VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 not attached: attaching. refcount now 1
[20131218T17:44:21.864Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|mlvm] Using dm_name=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 (use_tmp=false)
[20131218T17:44:21.864Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|host] attach_lv: released the mutex
[20131218T17:44:21.868Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdSlave] s_mutex lock: attach_from_sai
[20131218T17:44:21.868Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|nmutex] wait: reason=Adding info to s_attached_vdis
[20131218T17:44:21.869Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:21.869Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|nmutex] wait: reason=Removing from master_approved_ops
[20131218T17:44:21.869Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdSlave] Removing my current op
[20131218T17:44:21.869Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:21.869Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|nmutex] About to broadcast
[20131218T17:44:21.869Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|nmutex] Done
[20131218T17:44:21.869Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:21.869Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|nmutex] wait: reason=Removing from current_operations
[20131218T17:44:21.869Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdSlave] Removing my current op
[20131218T17:44:21.869Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:21.869Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|nmutex] About to broadcast
[20131218T17:44:21.869Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|nmutex] Done
[20131218T17:44:21.869Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|19 inet-rpc|7dad60af-c97a-4635-a46d-0a3ddfe58e6b|vhdd] Response: (omitted)
[20131218T17:44:21.870Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 413 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:21.870Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:21.870Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.activate</methodName><params><param><value><struct><member><name>dbg</name><value>dbg</value></member><member><name>dp</name><value>04385b43-bc7b-4ca5-a23a-361c99f6189c</value></member><member><name>sr</name><value>1</value></member><member><name>vdi</name><value>04385b43-bc7b-4ca5-a23a-361c99f6189c</value></member></struct></value></param></params></methodCall>
[20131218T17:44:21.871Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|vhdsm] API call: VDI.activate sr=1 vdi=04385b43-bc7b-4ca5-a23a-361c99f6189c
[20131218T17:44:21.871Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:21.871Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|nmutex] wait: reason=Adding to current_operations
[20131218T17:44:21.871Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|vhdSlave] Checking current ops
[20131218T17:44:21.871Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:21.871Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|nmutex] wait: reason=Checking whether the VDI is activated
[20131218T17:44:21.871Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:21.871Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|nmutex] wait: reason=Executing with operation '"OpActivating"'
[20131218T17:44:21.871Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:21.871Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|nmutex] wait: reason=Update id_map
[20131218T17:44:21.871Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|locking] update_leaf: vdi_location=04385b43-bc7b-4ca5-a23a-361c99f6189c
[20131218T17:44:21.871Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|nmutex] wait: reason=Finished op '"OpActivating"'. Removing from cur
[20131218T17:44:21.871Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|nmutex] About to broadcast
[20131218T17:44:21.871Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|nmutex] Done
[20131218T17:44:21.871Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:21.871Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|nmutex] wait: reason=Adding to master_approved_ops
[20131218T17:44:21.871Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|vhdSlave] Checking current ops
[20131218T17:44:21.871Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:21.871Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|nmutex] wait: reason=Activating tapdisk
[20131218T17:44:21.872Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|tapdisk_listen] Registered to listen to /dev/shm/1_1_04385b43-bc7b-4ca5-a23a-361c99f6189c.stats
[20131218T17:44:21.872Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|vhdSlave] Setting maxsize in shared page
[20131218T17:44:21.872Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|vhdSlave] Setting maxsize=58720256
[20131218T17:44:21.872Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:21.872Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|nmutex] wait: reason=Removing from master_approved_ops
[20131218T17:44:21.872Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|vhdSlave] Removing my current op
[20131218T17:44:21.872Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:21.872Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|nmutex] About to broadcast
[20131218T17:44:21.872Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|nmutex] Done
[20131218T17:44:21.872Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:21.872Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|nmutex] wait: reason=Removing from current_operations
[20131218T17:44:21.872Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|vhdSlave] Removing my current op
[20131218T17:44:21.872Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:21.872Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|nmutex] About to broadcast
[20131218T17:44:21.872Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|nmutex] Done
[20131218T17:44:21.873Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|20 inet-rpc|cde7740a-e5ad-4fef-843e-da77a8ecf4a4|vhdd] Response: (omitted)
[20131218T17:44:21.874Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc||http] Request { frame = false; method = POST; uri = /internal; query = [  ]; content_length = [ 156 ]; transfer encoding = ; version = 1.0; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = ; user_agent = xen-api-libs/1.0 }
[20131218T17:44:21.874Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc||vhdd] Internal handler
[20131218T17:44:21.874Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc||vhdd] Call={"method": "Debug.write_junk", "params": [{"sr": "1", "vdi": "04385b43-bc7b-4ca5-a23a-361c99f6189c", "size": 41943040, "n": 10, "current": []}], "id": 1149}
[20131218T17:44:21.874Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc||vhdsm] Writing junk
[20131218T17:44:21.874Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|21 inet-rpc||vhdd] Response: {"result": [], "error": null, "id": 0}
[20131218T17:44:21.875Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 415 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:21.875Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:21.875Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.deactivate</methodName><params><param><value><struct><member><name>dbg</name><value>dbg</value></member><member><name>dp</name><value>04385b43-bc7b-4ca5-a23a-361c99f6189c</value></member><member><name>sr</name><value>1</value></member><member><name>vdi</name><value>04385b43-bc7b-4ca5-a23a-361c99f6189c</value></member></struct></value></param></params></methodCall>
[20131218T17:44:21.875Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|vhdsm] API call: VDI.deactivate sr=1 vdi=04385b43-bc7b-4ca5-a23a-361c99f6189c
[20131218T17:44:21.875Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:21.875Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|nmutex] wait: reason=Adding to current_operations
[20131218T17:44:21.875Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|vhdSlave] Checking current ops
[20131218T17:44:21.875Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:21.875Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|nmutex] wait: reason=Deactivating
[20131218T17:44:21.875Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|tapdisk_listen] Unregistering 1/04385b43-bc7b-4ca5-a23a-361c99f6189c
[20131218T17:44:21.876Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:21.876Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|nmutex] wait: reason=Executing with operation '"OpDeactivating"'
[20131218T17:44:21.876Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:21.876Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|nmutex] wait: reason=Update id_map
[20131218T17:44:21.876Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|locking] update_leaf: vdi_location=04385b43-bc7b-4ca5-a23a-361c99f6189c
[20131218T17:44:21.876Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|nmutex] wait: reason=Finished op '"OpDeactivating"'. Removing from cur
[20131218T17:44:21.876Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|nmutex] About to broadcast
[20131218T17:44:21.876Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|nmutex] Done
[20131218T17:44:21.876Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:21.876Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|nmutex] wait: reason=Removing from current_operations
[20131218T17:44:21.876Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|vhdSlave] Removing my current op
[20131218T17:44:21.876Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:21.876Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|nmutex] About to broadcast
[20131218T17:44:21.876Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|nmutex] Done
[20131218T17:44:21.877Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|22 inet-rpc|c9d9bd44-5a55-4570-bf10-0930f98e2aeb|vhdd] Response: (omitted)
[20131218T17:44:21.878Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 411 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:21.878Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:21.878Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.detach</methodName><params><param><value><struct><member><name>dbg</name><value>dbg</value></member><member><name>dp</name><value>04385b43-bc7b-4ca5-a23a-361c99f6189c</value></member><member><name>sr</name><value>1</value></member><member><name>vdi</name><value>04385b43-bc7b-4ca5-a23a-361c99f6189c</value></member></struct></value></param></params></methodCall>
[20131218T17:44:21.878Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|vhdsm] API call: VDI.detach sr=1 vdi=04385b43-bc7b-4ca5-a23a-361c99f6189c
[20131218T17:44:21.878Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:21.878Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|nmutex] wait: reason=Adding to current_operations
[20131218T17:44:21.878Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|vhdSlave] Checking current ops
[20131218T17:44:21.878Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:21.878Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|nmutex] wait: reason=Checking we're attached
[20131218T17:44:21.878Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|nmutex] wait: reason=Deactivating tapdisk if necessary
[20131218T17:44:21.881Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:21.881Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|nmutex] wait: reason=Executing with operation '"OpDetaching"'
[20131218T17:44:21.881Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:21.881Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|nmutex] wait: reason=Update id_map
[20131218T17:44:21.881Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|locking] update_leaf: vdi_location=04385b43-bc7b-4ca5-a23a-361c99f6189c
[20131218T17:44:21.881Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|nmutex] wait: reason=Getting VHD uid='26d5a422-bac7-4d28-aaaa-2c56d610f77f'
[20131218T17:44:21.881Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|vhdMaster_utils] Resizing VHD uid: 26d5a422-bac7-4d28-aaaa-2c56d610f77f
[20131218T17:44:21.881Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:21.881Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|mlvm] Using dm_name=11d13e75-ea25-4115-bdb9-6067286fe76d (use_tmp=true)
[20131218T17:44:21.882Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|vhdutil] Dump size: overhead=4311040 phys_size=4311040 virtual_size=52428800 critical_size=56739840
[20131218T17:44:21.882Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|vhdutil] leaf_status: Some false reservation_type: Thin
[20131218T17:44:21.882Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:21.882Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|vhdMaster_utils] new_size=old_size=58720256. Not doing anything
[20131218T17:44:21.882Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|nmutex] wait: reason=Finished op '"OpDetaching"'. Removing from cur
[20131218T17:44:21.882Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|nmutex] About to broadcast
[20131218T17:44:21.882Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|nmutex] Done
[20131218T17:44:21.882Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:21.882Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|nmutex] wait: reason=Adding to master_approved_ops
[20131218T17:44:21.882Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|vhdSlave] Checking current ops
[20131218T17:44:21.882Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:21.882Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|nmutex] wait: reason=Reloading attach info
[20131218T17:44:21.882Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|host] Remove LV: refcount for dm=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 is now 0
[20131218T17:44:21.882Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|host] Removing LV=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549
[20131218T17:44:21.882Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|nmutex] wait: reason=Removing attach info
[20131218T17:44:21.883Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:21.883Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|nmutex] wait: reason=Removing from master_approved_ops
[20131218T17:44:21.883Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|vhdSlave] Removing my current op
[20131218T17:44:21.883Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:21.883Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|nmutex] About to broadcast
[20131218T17:44:21.883Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|nmutex] Done
[20131218T17:44:21.883Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:21.883Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|nmutex] wait: reason=Removing from current_operations
[20131218T17:44:21.883Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|vhdSlave] Removing my current op
[20131218T17:44:21.883Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:21.883Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|nmutex] About to broadcast
[20131218T17:44:21.883Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|nmutex] Done
[20131218T17:44:21.883Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|23 inet-rpc|dbbdd864-9c23-45ae-a89d-79003249ecc6|vhdd] Response: (omitted)
[20131218T17:44:21.885Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|24 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 326 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:21.885Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|24 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:21.885Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|24 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.stat</methodName><params><param><value><struct><member><name>dbg</name><value>dbg</value></member><member><name>sr</name><value>1</value></member><member><name>vdi</name><value>04385b43-bc7b-4ca5-a23a-361c99f6189c</value></member></struct></value></param></params></methodCall>
[20131218T17:44:21.885Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|24 inet-rpc|5d6b685a-444a-49b8-a4a9-79f361ab1554|vhdsm] API call: VDI.stat
[20131218T17:44:21.885Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|24 inet-rpc|5d6b685a-444a-49b8-a4a9-79f361ab1554|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:21.885Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|24 inet-rpc|5d6b685a-444a-49b8-a4a9-79f361ab1554|nmutex] wait: reason=Getting VHD uid='26d5a422-bac7-4d28-aaaa-2c56d610f77f'
[20131218T17:44:21.885Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|24 inet-rpc|5d6b685a-444a-49b8-a4a9-79f361ab1554|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:21.885Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|24 inet-rpc|5d6b685a-444a-49b8-a4a9-79f361ab1554|vhdd] Response: (omitted)
[20131218T17:44:21.886Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 1260 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:21.887Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:21.887Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.snapshot</methodName><params><param><value><struct><member><name>dbg</name><value>dbg</value></member><member><name>sr</name><value>1</value></member><member><name>vdi_info</name><value><struct><member><name>vdi</name><value>04385b43-bc7b-4ca5-a23a-361c99f6189c</value></member><member><name>content_id</name><value></value></member><member><name>name_label</name><value>ftest_vdi</value></member><member><name>name_description</name><value></value></member><member><name>ty</name><value>user</value></member><member><name>metadata_of_pool</name><value></value></member><member><name>is_a_snapshot</name><value><boolean>0</boolean></value></member><member><name>snapshot_time</name><value>19700101T00:00:00Z</value></member><member><name>snapshot_of</name><value></value></member><member><name>read_only</name><value><boolean>0</boolean></value></member><member><name>virtual_size</name><value>52428800</value></member><member><name>physical_utilisation</name><value>58720256</value></member><member><name>persistent</name><value><boolean>1</boolean></value></member><member><name>sm_config</name><value><struct></struct></value></member></struct></value></member></struct></value></param></params></methodCall>
[20131218T17:44:21.887Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdsm] API call: VDI.snapshot sr=1 vdi=04385b43-bc7b-4ca5-a23a-361c99f6189c
[20131218T17:44:21.887Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdmaster] Clone: Checking all hosts present
[20131218T17:44:21.887Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Retrieving the hashtbl of attached hosts
[20131218T17:44:21.887Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdmaster] OK
[20131218T17:44:21.887Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:21.887Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Executing with operation '"OpClone"'
[20131218T17:44:21.887Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:21.887Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Getting VHD uid='26d5a422-bac7-4d28-aaaa-2c56d610f77f'
[20131218T17:44:21.887Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|clone] Leaf clone: creating new leaf vhd for original VDI
[20131218T17:44:21.887Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] Dump size: overhead=4312576 phys_size=4312576 virtual_size=52428800 critical_size=109170176
[20131218T17:44:21.887Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] leaf_status: Some false reservation_type: Thin
[20131218T17:44:21.887Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdMaster_utils] Create child: maybe about to create a LV, size=58720256
[20131218T17:44:21.888Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:21.888Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|mlvm] LVM REDO: 000000000138„•¦¾   v      3   ' E 	(VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b 	&MGZKgc-lyql-P7hw-GH02-acPB-ns16-3EZmzN  #pv0 _j        _j        @
[20131218T17:44:21.888Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdMaster_utils] Created LVM volume with uuid=8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:21.888Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:21.888Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] attach_lv: Got the mutex
[20131218T17:44:21.888Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] LV VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 not attached: attaching. refcount now 1
[20131218T17:44:21.888Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|mlvm] Using dm_name=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 (use_tmp=false)
[20131218T17:44:21.888Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] attach_lv: released the mutex
[20131218T17:44:21.888Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:21.888Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] attach_lv: Got the mutex
[20131218T17:44:21.888Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] LV VG_XenStorage--1-VHD--8c50892f--18da--49d0--ba1a--2253a5dd350b not attached: attaching. refcount now 1
[20131218T17:44:21.888Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|mlvm] Using dm_name=VG_XenStorage--1-VHD--8c50892f--18da--49d0--ba1a--2253a5dd350b (use_tmp=false)
[20131218T17:44:21.890Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] attach_lv: released the mutex
[20131218T17:44:21.953Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] query_size_vhd: Querying size of VHD e77c8668-3bd8-4b1c-9c02-7a90d9e5355a
[20131218T17:44:21.953Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] query_size_vhd: get_phys_size returned 4312576
[20131218T17:44:21.953Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] query_size_vhd: first_allocated_block=None
[20131218T17:44:21.953Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] query_size_vhd: virtual_size=52428800
[20131218T17:44:21.956Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] Remove LV: refcount for dm=VG_XenStorage--1-VHD--8c50892f--18da--49d0--ba1a--2253a5dd350b is now 0
[20131218T17:44:21.956Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] Removing LV=VG_XenStorage--1-VHD--8c50892f--18da--49d0--ba1a--2253a5dd350b
[20131218T17:44:21.956Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] Remove LV: refcount for dm=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 is now 0
[20131218T17:44:21.956Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] Removing LV=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549
[20131218T17:44:21.956Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Adding VHD uid='e77c8668-3bd8-4b1c-9c02-7a90d9e5355a'
[20131218T17:44:21.956Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdMaster_utils] New VHD inserted into Hashtbl uid=e77c8668-3bd8-4b1c-9c02-7a90d9e5355a
[20131218T17:44:21.956Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Remapping an ID (04385b43-bc7b-4ca5-a23a-361c99f6189c->PVhd 'e77c8668-3bd8-4b1c-9c02-7a90d9e5355a')
[20131218T17:44:21.956Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: id_to_leaf_mapping
[20131218T17:44:21.956Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] attach_lv: Got the mutex
[20131218T17:44:21.957Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] LV VG_XenStorage--1-id_to_leaf_mapping not attached: attaching. refcount now 1
[20131218T17:44:21.957Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|mlvm] Using dm_name=VG_XenStorage--1-id_to_leaf_mapping (use_tmp=false)
[20131218T17:44:21.957Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] attach_lv: released the mutex
[20131218T17:44:21.957Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] Remove LV: refcount for dm=VG_XenStorage--1-id_to_leaf_mapping is now 0
[20131218T17:44:21.957Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] Removing LV=VG_XenStorage--1-id_to_leaf_mapping
[20131218T17:44:21.957Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdMaster_utils] Calling reattach
[20131218T17:44:21.957Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:21.957Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Executing with operation '"OpReattaching"'
[20131218T17:44:21.957Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:21.957Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Getting VHD uid='e77c8668-3bd8-4b1c-9c02-7a90d9e5355a'
[20131218T17:44:21.957Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdMaster_utils] Resizing VHD uid: e77c8668-3bd8-4b1c-9c02-7a90d9e5355a
[20131218T17:44:21.957Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:21.957Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|mlvm] Using dm_name=30cd4388-b6a3-476d-ba94-3f114386673d (use_tmp=true)
[20131218T17:44:21.958Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] Dump size: overhead=4312576 phys_size=4312576 virtual_size=52428800 critical_size=56741376
[20131218T17:44:21.958Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] leaf_status: Some false reservation_type: Thin
[20131218T17:44:21.958Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:21.958Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdMaster_utils] new_size=old_size=58720256. Not doing anything
[20131218T17:44:21.958Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Getting a copy of a VHD chain
[20131218T17:44:21.958Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:21.958Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:21.958Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:21.958Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:21.958Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Finished op '"OpReattaching"'. Removing from cur
[20131218T17:44:21.958Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] About to broadcast
[20131218T17:44:21.958Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] Done
[20131218T17:44:21.959Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|clone] Creating new leaf for new VDI
[20131218T17:44:21.959Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] Dump size: overhead=4312576 phys_size=4312576 virtual_size=52428800 critical_size=109170176
[20131218T17:44:21.959Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] leaf_status: Some false reservation_type: Attach
[20131218T17:44:21.959Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdMaster_utils] Create child: maybe about to create a LV, size=8388608
[20131218T17:44:21.959Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-566c9fd3-078c-4f14-81e2-c3ccdbc2f028
[20131218T17:44:21.959Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|mlvm] LVM REDO: 000000000138„•¦¾   v      3   ' F 	(VHD-566c9fd3-078c-4f14-81e2-c3ccdbc2f028 	&kDOi1n-yjB0-pLKJ-L5Jb-koNx-5dHS-UrLdoU  #pv0 _j        _j        @
[20131218T17:44:21.959Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdMaster_utils] Created LVM volume with uuid=566c9fd3-078c-4f14-81e2-c3ccdbc2f028
[20131218T17:44:21.959Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:21.959Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] attach_lv: Got the mutex
[20131218T17:44:21.959Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] LV VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 not attached: attaching. refcount now 1
[20131218T17:44:21.959Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|mlvm] Using dm_name=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 (use_tmp=false)
[20131218T17:44:21.959Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] attach_lv: released the mutex
[20131218T17:44:21.959Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-566c9fd3-078c-4f14-81e2-c3ccdbc2f028
[20131218T17:44:21.959Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] attach_lv: Got the mutex
[20131218T17:44:21.959Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] LV VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028 not attached: attaching. refcount now 1
[20131218T17:44:21.960Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|mlvm] Using dm_name=VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028 (use_tmp=false)
[20131218T17:44:21.960Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] attach_lv: released the mutex
[20131218T17:44:21.997Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] query_size_vhd: Querying size of VHD 46483369-750d-41f4-8409-6c83f65aabad
[20131218T17:44:21.998Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] query_size_vhd: get_phys_size returned 4312576
[20131218T17:44:21.998Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] query_size_vhd: first_allocated_block=None
[20131218T17:44:21.998Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] query_size_vhd: virtual_size=52428800
[20131218T17:44:22.001Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] Remove LV: refcount for dm=VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028 is now 0
[20131218T17:44:22.001Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] Removing LV=VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028
[20131218T17:44:22.001Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] Remove LV: refcount for dm=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 is now 0
[20131218T17:44:22.001Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] Removing LV=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549
[20131218T17:44:22.001Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Adding VHD uid='46483369-750d-41f4-8409-6c83f65aabad'
[20131218T17:44:22.001Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdMaster_utils] New VHD inserted into Hashtbl uid=46483369-750d-41f4-8409-6c83f65aabad
[20131218T17:44:22.001Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Getting VHD uid='26d5a422-bac7-4d28-aaaa-2c56d610f77f'
[20131218T17:44:22.001Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdMaster_utils] Calling set_hidden on VHD uid=26d5a422-bac7-4d28-aaaa-2c56d610f77f
[20131218T17:44:22.002Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:22.002Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] attach_lv: Got the mutex
[20131218T17:44:22.002Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] LV VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 not attached: attaching. refcount now 1
[20131218T17:44:22.002Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|mlvm] Using dm_name=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 (use_tmp=false)
[20131218T17:44:22.002Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] attach_lv: released the mutex
[20131218T17:44:22.002Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] query_size_vhd: Querying size of VHD 26d5a422-bac7-4d28-aaaa-2c56d610f77f
[20131218T17:44:22.002Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] query_size_vhd: get_phys_size returned 4311040
[20131218T17:44:22.002Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] query_size_vhd: first_allocated_block=None
[20131218T17:44:22.002Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] query_size_vhd: virtual_size=52428800
[20131218T17:44:22.006Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] Remove LV: refcount for dm=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 is now 0
[20131218T17:44:22.006Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] Removing LV=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549
[20131218T17:44:22.006Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdMaster_utils] Resizing VHD uid: 26d5a422-bac7-4d28-aaaa-2c56d610f77f
[20131218T17:44:22.006Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:22.006Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|mlvm] Using dm_name=2f1b5209-3baf-4e3a-97d1-3a4343913913 (use_tmp=true)
[20131218T17:44:22.009Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] Dump size: overhead=4311040 phys_size=4311040 virtual_size=52428800 critical_size=56739840
[20131218T17:44:22.009Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] leaf_status: None reservation_type: Thin
[20131218T17:44:22.009Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:22.009Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdMaster_utils] old_size=58720256 new_size=8388608
[20131218T17:44:22.009Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:22.009Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|mlvm] Beginning reduce_size_to:
[20131218T17:44:22.009Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|mlvm] Lv.reduce_size_to: s.s_start_extent=0 s.s_extent_count=14 left=2
[20131218T17:44:22.010Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|mlvm] LVM REDO: 000000000078„•¦¾   :          G¡	(VHD-3b7ce781-fa29-42a4-ab34-e8655251f549_j        
[20131218T17:44:22.010Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:22.010Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:22.010Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] attach_lv: Got the mutex
[20131218T17:44:22.010Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] LV VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 not attached: attaching. refcount now 1
[20131218T17:44:22.010Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|mlvm] Using dm_name=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 (use_tmp=false)
[20131218T17:44:22.010Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] attach_lv: released the mutex
[20131218T17:44:22.013Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] Remove LV: refcount for dm=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 is now 0
[20131218T17:44:22.013Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] Removing LV=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549
[20131218T17:44:22.013Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdMaster_utils] Calling reattach
[20131218T17:44:22.014Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.014Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Executing with operation '"OpReattaching"'
[20131218T17:44:22.014Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.014Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Getting VHD uid='e77c8668-3bd8-4b1c-9c02-7a90d9e5355a'
[20131218T17:44:22.014Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdMaster_utils] Resizing VHD uid: e77c8668-3bd8-4b1c-9c02-7a90d9e5355a
[20131218T17:44:22.014Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:22.014Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|mlvm] Using dm_name=2b17cb86-118e-4532-8c60-1d69f6ea2597 (use_tmp=true)
[20131218T17:44:22.015Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] Dump size: overhead=4312576 phys_size=4312576 virtual_size=52428800 critical_size=56741376
[20131218T17:44:22.015Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdutil] leaf_status: Some false reservation_type: Thin
[20131218T17:44:22.015Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:22.015Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdMaster_utils] new_size=old_size=58720256. Not doing anything
[20131218T17:44:22.015Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Getting a copy of a VHD chain
[20131218T17:44:22.015Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:22.015Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:22.015Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:22.015Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:22.015Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Finished op '"OpReattaching"'. Removing from cur
[20131218T17:44:22.015Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] About to broadcast
[20131218T17:44:22.015Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] Done
[20131218T17:44:22.016Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Update_vhd_size uid='26d5a422-bac7-4d28-aaaa-2c56d610f77f'
[20131218T17:44:22.016Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhd_records] newsize=overhead=4311040 phys_size=4311040 virtual_size=52428800 critical_size=56739840
[20131218T17:44:22.016Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Update_hidden ptr='["PVhd", "26d5a422-bac7-4d28-aaaa-2c56d610f77f"]' hidden=2
[20131218T17:44:22.016Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|clone] Marked vhd: 26d5a422-bac7-4d28-aaaa-2c56d610f77f as hidden=2
[20131218T17:44:22.016Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|coalesce] Beginning relink phase of vhd: 26d5a422-bac7-4d28-aaaa-2c56d610f77f
[20131218T17:44:22.016Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Finding the children of parent ["PVhd", "26d5a422-bac7-4d28-aaaa-2c56d610f77f"]
[20131218T17:44:22.016Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Getting VHD uid='26d5a422-bac7-4d28-aaaa-2c56d610f77f'
[20131218T17:44:22.016Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Adding a new ID to the mapping (f97ed720-a6ec-4822-82d9-95b20940cb5b->PVhd '46483369-750d-41f4-8409-6c83f65aabad')
[20131218T17:44:22.016Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|lvmabs] operating on vg: VG_XenStorage-1 lv: id_to_leaf_mapping
[20131218T17:44:22.016Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] attach_lv: Got the mutex
[20131218T17:44:22.016Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] LV VG_XenStorage--1-id_to_leaf_mapping not attached: attaching. refcount now 1
[20131218T17:44:22.016Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|mlvm] Using dm_name=VG_XenStorage--1-id_to_leaf_mapping (use_tmp=false)
[20131218T17:44:22.016Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] attach_lv: released the mutex
[20131218T17:44:22.016Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] Remove LV: refcount for dm=VG_XenStorage--1-id_to_leaf_mapping is now 0
[20131218T17:44:22.016Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|host] Removing LV=VG_XenStorage--1-id_to_leaf_mapping
[20131218T17:44:22.017Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] wait: reason=Finished op '"OpClone"'. Removing from cur
[20131218T17:44:22.017Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] About to broadcast
[20131218T17:44:22.017Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|nmutex] Done
[20131218T17:44:22.017Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|25 inet-rpc|a49bd301-2d47-4f96-bfe9-26a240c62f4a|vhdd] Response: (omitted)
[20131218T17:44:22.019Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 486 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:22.019Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:22.019Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.attach</methodName><params><param><value><struct><member><name>dbg</name><value>dbg</value></member><member><name>dp</name><value>04385b43-bc7b-4ca5-a23a-361c99f6189c</value></member><member><name>sr</name><value>1</value></member><member><name>vdi</name><value>04385b43-bc7b-4ca5-a23a-361c99f6189c</value></member><member><name>read_write</name><value><boolean>1</boolean></value></member></struct></value></param></params></methodCall>
[20131218T17:44:22.019Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdsm] API call: VDI.attach sr=1 vdi=04385b43-bc7b-4ca5-a23a-361c99f6189c writable=true
[20131218T17:44:22.019Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:22.019Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|nmutex] wait: reason=Adding to current_operations
[20131218T17:44:22.019Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdSlave] Checking current ops
[20131218T17:44:22.019Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:22.019Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|nmutex] wait: reason=Finding whether we're already attached
[20131218T17:44:22.019Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|nmutex] wait: reason=Retrieving the hashtbl of attached hosts
[20131218T17:44:22.019Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdmaster] Got to the slave_attach function call
[20131218T17:44:22.019Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.019Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|nmutex] wait: reason=Executing with operation '"OpAttaching"'
[20131218T17:44:22.019Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.019Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|nmutex] wait: reason=Getting VHD uid='e77c8668-3bd8-4b1c-9c02-7a90d9e5355a'
[20131218T17:44:22.019Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdMaster_utils] Resizing VHD uid: e77c8668-3bd8-4b1c-9c02-7a90d9e5355a
[20131218T17:44:22.020Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:22.020Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|mlvm] Using dm_name=a1b6901c-97b1-47ed-a3c0-0e797e73d414 (use_tmp=true)
[20131218T17:44:22.020Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdutil] Dump size: overhead=4312576 phys_size=4312576 virtual_size=52428800 critical_size=56741376
[20131218T17:44:22.020Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdutil] leaf_status: Some true reservation_type: Thin
[20131218T17:44:22.020Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:22.020Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdMaster_utils] new_size=old_size=58720256. Not doing anything
[20131218T17:44:22.020Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|nmutex] wait: reason=Update id_map
[20131218T17:44:22.020Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|locking] update_leaf: vdi_location=04385b43-bc7b-4ca5-a23a-361c99f6189c
[20131218T17:44:22.020Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|nmutex] wait: reason=Finished op '"OpAttaching"'. Removing from cur
[20131218T17:44:22.020Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|nmutex] About to broadcast
[20131218T17:44:22.020Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|nmutex] Done
[20131218T17:44:22.020Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|nmutex] wait: reason=Getting a copy of a VHD chain
[20131218T17:44:22.020Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:22.020Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:22.020Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:22.020Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:22.021Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdSlave] Got response: leaf=/tmp/dummytest/1//dev/mapper/VG_XenStorage--1-VHD--8c50892f--18da--49d0--ba1a--2253a5dd350b
[20131218T17:44:22.021Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:22.021Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|nmutex] wait: reason=Adding to master_approved_ops
[20131218T17:44:22.021Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdSlave] Checking current ops
[20131218T17:44:22.021Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:22.021Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdSlave] LV name: VG_XenStorage--1-VHD--8c50892f--18da--49d0--ba1a--2253a5dd350b
[20131218T17:44:22.021Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdSlave] LV name: VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549
[20131218T17:44:22.021Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|host] attach_lv: Got the mutex
[20131218T17:44:22.021Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|host] LV VG_XenStorage--1-VHD--8c50892f--18da--49d0--ba1a--2253a5dd350b not attached: attaching. refcount now 1
[20131218T17:44:22.021Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|mlvm] Using dm_name=VG_XenStorage--1-VHD--8c50892f--18da--49d0--ba1a--2253a5dd350b (use_tmp=false)
[20131218T17:44:22.021Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|host] attach_lv: released the mutex
[20131218T17:44:22.021Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|host] attach_lv: Got the mutex
[20131218T17:44:22.021Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|host] LV VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 not attached: attaching. refcount now 1
[20131218T17:44:22.021Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|mlvm] Using dm_name=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 (use_tmp=false)
[20131218T17:44:22.021Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|host] attach_lv: released the mutex
[20131218T17:44:22.022Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdSlave] s_mutex lock: attach_from_sai
[20131218T17:44:22.022Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|nmutex] wait: reason=Adding info to s_attached_vdis
[20131218T17:44:22.022Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:22.022Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|nmutex] wait: reason=Removing from master_approved_ops
[20131218T17:44:22.022Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdSlave] Removing my current op
[20131218T17:44:22.022Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:22.022Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|nmutex] About to broadcast
[20131218T17:44:22.022Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|nmutex] Done
[20131218T17:44:22.022Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:22.023Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|nmutex] wait: reason=Removing from current_operations
[20131218T17:44:22.023Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdSlave] Removing my current op
[20131218T17:44:22.023Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:22.023Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|nmutex] About to broadcast
[20131218T17:44:22.023Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|nmutex] Done
[20131218T17:44:22.023Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|26 inet-rpc|a2c44580-75a7-4469-88ed-af29f73e33c5|vhdd] Response: (omitted)
[20131218T17:44:22.024Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 413 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:22.025Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:22.025Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.activate</methodName><params><param><value><struct><member><name>dbg</name><value>dbg</value></member><member><name>dp</name><value>04385b43-bc7b-4ca5-a23a-361c99f6189c</value></member><member><name>sr</name><value>1</value></member><member><name>vdi</name><value>04385b43-bc7b-4ca5-a23a-361c99f6189c</value></member></struct></value></param></params></methodCall>
[20131218T17:44:22.025Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|vhdsm] API call: VDI.activate sr=1 vdi=04385b43-bc7b-4ca5-a23a-361c99f6189c
[20131218T17:44:22.025Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:22.025Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|nmutex] wait: reason=Adding to current_operations
[20131218T17:44:22.025Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|vhdSlave] Checking current ops
[20131218T17:44:22.025Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:22.025Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|nmutex] wait: reason=Checking whether the VDI is activated
[20131218T17:44:22.025Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.025Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|nmutex] wait: reason=Executing with operation '"OpActivating"'
[20131218T17:44:22.025Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.025Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|nmutex] wait: reason=Update id_map
[20131218T17:44:22.025Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|locking] update_leaf: vdi_location=04385b43-bc7b-4ca5-a23a-361c99f6189c
[20131218T17:44:22.026Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|nmutex] wait: reason=Finished op '"OpActivating"'. Removing from cur
[20131218T17:44:22.026Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|nmutex] About to broadcast
[20131218T17:44:22.026Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|nmutex] Done
[20131218T17:44:22.026Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:22.026Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|nmutex] wait: reason=Adding to master_approved_ops
[20131218T17:44:22.026Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|vhdSlave] Checking current ops
[20131218T17:44:22.026Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:22.026Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|nmutex] wait: reason=Activating tapdisk
[20131218T17:44:22.027Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|tapdisk_listen] Registered to listen to /dev/shm/1_1_04385b43-bc7b-4ca5-a23a-361c99f6189c.stats
[20131218T17:44:22.027Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|vhdSlave] Setting maxsize in shared page
[20131218T17:44:22.027Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|vhdSlave] Setting maxsize=58720256
[20131218T17:44:22.027Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:22.027Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|nmutex] wait: reason=Removing from master_approved_ops
[20131218T17:44:22.027Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|vhdSlave] Removing my current op
[20131218T17:44:22.027Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:22.027Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|nmutex] About to broadcast
[20131218T17:44:22.027Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|nmutex] Done
[20131218T17:44:22.027Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:22.027Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|nmutex] wait: reason=Removing from current_operations
[20131218T17:44:22.027Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|vhdSlave] Removing my current op
[20131218T17:44:22.027Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:22.027Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|nmutex] About to broadcast
[20131218T17:44:22.027Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|nmutex] Done
[20131218T17:44:22.028Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|27 inet-rpc|5de048bf-f13f-494d-ae68-ec3f04a0b891|vhdd] Response: (omitted)
[20131218T17:44:22.029Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc||http] Request { frame = false; method = POST; uri = /internal; query = [  ]; content_length = [ 144 ]; transfer encoding = ; version = 1.0; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = ; user_agent = xen-api-libs/1.0 }
[20131218T17:44:22.029Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc||vhdd] Internal handler
[20131218T17:44:22.029Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc||vhdd] Call={"method": "Debug.check_junk", "params": [{"sr": "1", "vdi": "04385b43-bc7b-4ca5-a23a-361c99f6189c", "current": [[[[0, 10]], 55]]}], "id": 1150}
[20131218T17:44:22.029Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc||vhdsm] Checking junk
[20131218T17:44:22.029Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc||vhdsm] Junk OK (1)
[20131218T17:44:22.029Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|28 inet-rpc||vhdd] Response: {"result": null, "error": null, "id": 0}
[20131218T17:44:22.031Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc||http] Request { frame = false; method = POST; uri = /internal; query = [  ]; content_length = [ 129 ]; transfer encoding = ; version = 1.0; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = ; user_agent = xen-api-libs/1.0 }
[20131218T17:44:22.031Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc||vhdd] Internal handler
[20131218T17:44:22.031Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc||vhdd] Call={"method": "Debug.check_junk", "params": [{"sr": "1", "vdi": "04385b43-bc7b-4ca5-a23a-361c99f6189c", "current": []}], "id": 1151}
[20131218T17:44:22.031Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc||vhdsm] Checking junk
[20131218T17:44:22.032Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc||vhdsm] Junk OK (0)
[20131218T17:44:22.032Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|29 inet-rpc||vhdd] Response: {"result": null, "error": null, "id": 0}
[20131218T17:44:22.033Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 415 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:22.033Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:22.033Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.deactivate</methodName><params><param><value><struct><member><name>dbg</name><value>dbg</value></member><member><name>dp</name><value>04385b43-bc7b-4ca5-a23a-361c99f6189c</value></member><member><name>sr</name><value>1</value></member><member><name>vdi</name><value>04385b43-bc7b-4ca5-a23a-361c99f6189c</value></member></struct></value></param></params></methodCall>
[20131218T17:44:22.033Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|vhdsm] API call: VDI.deactivate sr=1 vdi=04385b43-bc7b-4ca5-a23a-361c99f6189c
[20131218T17:44:22.033Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:22.033Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|nmutex] wait: reason=Adding to current_operations
[20131218T17:44:22.033Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|vhdSlave] Checking current ops
[20131218T17:44:22.033Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:22.033Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|nmutex] wait: reason=Deactivating
[20131218T17:44:22.033Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|tapdisk_listen] Unregistering 1/04385b43-bc7b-4ca5-a23a-361c99f6189c
[20131218T17:44:22.034Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.034Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|nmutex] wait: reason=Executing with operation '"OpDeactivating"'
[20131218T17:44:22.034Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.034Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|nmutex] wait: reason=Update id_map
[20131218T17:44:22.034Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|locking] update_leaf: vdi_location=04385b43-bc7b-4ca5-a23a-361c99f6189c
[20131218T17:44:22.034Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|nmutex] wait: reason=Finished op '"OpDeactivating"'. Removing from cur
[20131218T17:44:22.034Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|nmutex] About to broadcast
[20131218T17:44:22.034Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|nmutex] Done
[20131218T17:44:22.034Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:22.034Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|nmutex] wait: reason=Removing from current_operations
[20131218T17:44:22.034Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|vhdSlave] Removing my current op
[20131218T17:44:22.034Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:22.034Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|nmutex] About to broadcast
[20131218T17:44:22.034Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|nmutex] Done
[20131218T17:44:22.035Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|30 inet-rpc|dc377d88-45af-4294-adb2-eb24c551d1d8|vhdd] Response: (omitted)
[20131218T17:44:22.036Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 411 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:22.036Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:22.036Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.detach</methodName><params><param><value><struct><member><name>dbg</name><value>dbg</value></member><member><name>dp</name><value>04385b43-bc7b-4ca5-a23a-361c99f6189c</value></member><member><name>sr</name><value>1</value></member><member><name>vdi</name><value>04385b43-bc7b-4ca5-a23a-361c99f6189c</value></member></struct></value></param></params></methodCall>
[20131218T17:44:22.036Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|vhdsm] API call: VDI.detach sr=1 vdi=04385b43-bc7b-4ca5-a23a-361c99f6189c
[20131218T17:44:22.036Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:22.036Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|nmutex] wait: reason=Adding to current_operations
[20131218T17:44:22.036Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|vhdSlave] Checking current ops
[20131218T17:44:22.036Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:22.036Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|nmutex] wait: reason=Checking we're attached
[20131218T17:44:22.036Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|nmutex] wait: reason=Deactivating tapdisk if necessary
[20131218T17:44:22.037Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.037Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|nmutex] wait: reason=Executing with operation '"OpDetaching"'
[20131218T17:44:22.037Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.037Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|nmutex] wait: reason=Update id_map
[20131218T17:44:22.037Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|locking] update_leaf: vdi_location=04385b43-bc7b-4ca5-a23a-361c99f6189c
[20131218T17:44:22.037Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|nmutex] wait: reason=Getting VHD uid='e77c8668-3bd8-4b1c-9c02-7a90d9e5355a'
[20131218T17:44:22.037Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|vhdMaster_utils] Resizing VHD uid: e77c8668-3bd8-4b1c-9c02-7a90d9e5355a
[20131218T17:44:22.037Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:22.037Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|mlvm] Using dm_name=aa5e6ff0-dfaf-4f9f-952f-1f03c163b0fc (use_tmp=true)
[20131218T17:44:22.038Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|vhdutil] Dump size: overhead=4312576 phys_size=4312576 virtual_size=52428800 critical_size=56741376
[20131218T17:44:22.038Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|vhdutil] leaf_status: Some false reservation_type: Thin
[20131218T17:44:22.038Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:22.038Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|vhdMaster_utils] new_size=old_size=58720256. Not doing anything
[20131218T17:44:22.038Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|nmutex] wait: reason=Finished op '"OpDetaching"'. Removing from cur
[20131218T17:44:22.038Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|nmutex] About to broadcast
[20131218T17:44:22.038Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|nmutex] Done
[20131218T17:44:22.038Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:22.038Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|nmutex] wait: reason=Adding to master_approved_ops
[20131218T17:44:22.038Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|vhdSlave] Checking current ops
[20131218T17:44:22.038Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:22.038Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|nmutex] wait: reason=Reloading attach info
[20131218T17:44:22.038Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|host] Remove LV: refcount for dm=VG_XenStorage--1-VHD--8c50892f--18da--49d0--ba1a--2253a5dd350b is now 0
[20131218T17:44:22.038Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|host] Removing LV=VG_XenStorage--1-VHD--8c50892f--18da--49d0--ba1a--2253a5dd350b
[20131218T17:44:22.038Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|host] Remove LV: refcount for dm=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 is now 0
[20131218T17:44:22.038Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|host] Removing LV=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549
[20131218T17:44:22.038Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|nmutex] wait: reason=Removing attach info
[20131218T17:44:22.038Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:22.038Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|nmutex] wait: reason=Removing from master_approved_ops
[20131218T17:44:22.038Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|vhdSlave] Removing my current op
[20131218T17:44:22.039Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:22.039Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|nmutex] About to broadcast
[20131218T17:44:22.039Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|nmutex] Done
[20131218T17:44:22.039Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:22.039Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|nmutex] wait: reason=Removing from current_operations
[20131218T17:44:22.039Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|vhdSlave] Removing my current op
[20131218T17:44:22.039Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:22.039Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|nmutex] About to broadcast
[20131218T17:44:22.039Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|nmutex] Done
[20131218T17:44:22.039Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|31 inet-rpc|21410f81-0c5b-4032-9b95-878a30797ef3|vhdd] Response: (omitted)
[20131218T17:44:22.040Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 486 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:22.040Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:22.040Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.attach</methodName><params><param><value><struct><member><name>dbg</name><value>dbg</value></member><member><name>dp</name><value>f97ed720-a6ec-4822-82d9-95b20940cb5b</value></member><member><name>sr</name><value>1</value></member><member><name>vdi</name><value>f97ed720-a6ec-4822-82d9-95b20940cb5b</value></member><member><name>read_write</name><value><boolean>1</boolean></value></member></struct></value></param></params></methodCall>
[20131218T17:44:22.040Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdsm] API call: VDI.attach sr=1 vdi=f97ed720-a6ec-4822-82d9-95b20940cb5b writable=true
[20131218T17:44:22.040Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:22.040Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|nmutex] wait: reason=Adding to current_operations
[20131218T17:44:22.040Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdSlave] Checking current ops
[20131218T17:44:22.040Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:22.040Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|nmutex] wait: reason=Finding whether we're already attached
[20131218T17:44:22.041Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|nmutex] wait: reason=Retrieving the hashtbl of attached hosts
[20131218T17:44:22.041Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdmaster] Got to the slave_attach function call
[20131218T17:44:22.041Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.041Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|nmutex] wait: reason=Executing with operation '"OpAttaching"'
[20131218T17:44:22.041Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.041Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|nmutex] wait: reason=Getting VHD uid='46483369-750d-41f4-8409-6c83f65aabad'
[20131218T17:44:22.041Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdMaster_utils] Resizing VHD uid: 46483369-750d-41f4-8409-6c83f65aabad
[20131218T17:44:22.041Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-566c9fd3-078c-4f14-81e2-c3ccdbc2f028
[20131218T17:44:22.041Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|mlvm] Using dm_name=af77c482-9cf7-439d-badd-2ee28ee0339e (use_tmp=true)
[20131218T17:44:22.041Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdutil] Dump size: overhead=4312576 phys_size=4312576 virtual_size=52428800 critical_size=56741376
[20131218T17:44:22.041Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdutil] leaf_status: Some true reservation_type: Attach
[20131218T17:44:22.041Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-566c9fd3-078c-4f14-81e2-c3ccdbc2f028
[20131218T17:44:22.041Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdMaster_utils] old_size=8388608 new_size=58720256
[20131218T17:44:22.041Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-566c9fd3-078c-4f14-81e2-c3ccdbc2f028
[20131218T17:44:22.042Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|mlvm] LVM REDO: 000000000098„•¦¾   N   
   '     H¢	(VHD-566c9fd3-078c-4f14-81e2-c3ccdbc2f028  #pv0 _j        !_j        @
[20131218T17:44:22.042Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-566c9fd3-078c-4f14-81e2-c3ccdbc2f028
[20131218T17:44:22.042Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-566c9fd3-078c-4f14-81e2-c3ccdbc2f028
[20131218T17:44:22.042Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|host] attach_lv: Got the mutex
[20131218T17:44:22.042Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|host] LV VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028 not attached: attaching. refcount now 1
[20131218T17:44:22.042Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|mlvm] Using dm_name=VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028 (use_tmp=false)
[20131218T17:44:22.042Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|host] attach_lv: released the mutex
[20131218T17:44:22.049Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|host] Remove LV: refcount for dm=VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028 is now 0
[20131218T17:44:22.050Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|host] Removing LV=VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028
[20131218T17:44:22.050Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|nmutex] wait: reason=Update id_map
[20131218T17:44:22.050Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|locking] update_leaf: vdi_location=f97ed720-a6ec-4822-82d9-95b20940cb5b
[20131218T17:44:22.050Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|nmutex] wait: reason=Finished op '"OpAttaching"'. Removing from cur
[20131218T17:44:22.050Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|nmutex] About to broadcast
[20131218T17:44:22.050Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|nmutex] Done
[20131218T17:44:22.050Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|nmutex] wait: reason=Getting a copy of a VHD chain
[20131218T17:44:22.050Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-566c9fd3-078c-4f14-81e2-c3ccdbc2f028
[20131218T17:44:22.050Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-566c9fd3-078c-4f14-81e2-c3ccdbc2f028
[20131218T17:44:22.050Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-566c9fd3-078c-4f14-81e2-c3ccdbc2f028
[20131218T17:44:22.050Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-3b7ce781-fa29-42a4-ab34-e8655251f549
[20131218T17:44:22.050Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdSlave] Got response: leaf=/tmp/dummytest/1//dev/mapper/VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028
[20131218T17:44:22.050Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:22.050Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|nmutex] wait: reason=Adding to master_approved_ops
[20131218T17:44:22.050Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdSlave] Checking current ops
[20131218T17:44:22.051Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:22.051Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdSlave] LV name: VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028
[20131218T17:44:22.051Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdSlave] LV name: VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549
[20131218T17:44:22.051Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|host] attach_lv: Got the mutex
[20131218T17:44:22.051Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|host] LV VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028 not attached: attaching. refcount now 1
[20131218T17:44:22.051Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|mlvm] Using dm_name=VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028 (use_tmp=false)
[20131218T17:44:22.051Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|host] attach_lv: released the mutex
[20131218T17:44:22.051Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|host] attach_lv: Got the mutex
[20131218T17:44:22.051Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|host] LV VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 not attached: attaching. refcount now 1
[20131218T17:44:22.051Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|mlvm] Using dm_name=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 (use_tmp=false)
[20131218T17:44:22.051Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|host] attach_lv: released the mutex
[20131218T17:44:22.055Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdSlave] s_mutex lock: attach_from_sai
[20131218T17:44:22.055Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|nmutex] wait: reason=Adding info to s_attached_vdis
[20131218T17:44:22.055Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:22.055Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|nmutex] wait: reason=Removing from master_approved_ops
[20131218T17:44:22.055Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdSlave] Removing my current op
[20131218T17:44:22.055Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:22.055Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|nmutex] About to broadcast
[20131218T17:44:22.055Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|nmutex] Done
[20131218T17:44:22.055Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:22.055Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|nmutex] wait: reason=Removing from current_operations
[20131218T17:44:22.055Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdSlave] Removing my current op
[20131218T17:44:22.055Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:22.056Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|nmutex] About to broadcast
[20131218T17:44:22.056Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|nmutex] Done
[20131218T17:44:22.056Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|32 inet-rpc|f9b3b7f3-dfd7-4426-ba1b-8b0f30e1d65e|vhdd] Response: (omitted)
[20131218T17:44:22.057Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 413 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:22.057Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:22.057Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.activate</methodName><params><param><value><struct><member><name>dbg</name><value>dbg</value></member><member><name>dp</name><value>f97ed720-a6ec-4822-82d9-95b20940cb5b</value></member><member><name>sr</name><value>1</value></member><member><name>vdi</name><value>f97ed720-a6ec-4822-82d9-95b20940cb5b</value></member></struct></value></param></params></methodCall>
[20131218T17:44:22.057Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|vhdsm] API call: VDI.activate sr=1 vdi=f97ed720-a6ec-4822-82d9-95b20940cb5b
[20131218T17:44:22.057Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:22.057Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|nmutex] wait: reason=Adding to current_operations
[20131218T17:44:22.057Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|vhdSlave] Checking current ops
[20131218T17:44:22.058Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:22.058Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|nmutex] wait: reason=Checking whether the VDI is activated
[20131218T17:44:22.058Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.058Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|nmutex] wait: reason=Executing with operation '"OpActivating"'
[20131218T17:44:22.058Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.058Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|nmutex] wait: reason=Update id_map
[20131218T17:44:22.058Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|locking] update_leaf: vdi_location=f97ed720-a6ec-4822-82d9-95b20940cb5b
[20131218T17:44:22.058Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|nmutex] wait: reason=Finished op '"OpActivating"'. Removing from cur
[20131218T17:44:22.058Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|nmutex] About to broadcast
[20131218T17:44:22.058Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|nmutex] Done
[20131218T17:44:22.058Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:22.058Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|nmutex] wait: reason=Adding to master_approved_ops
[20131218T17:44:22.058Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|vhdSlave] Checking current ops
[20131218T17:44:22.058Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:22.058Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|nmutex] wait: reason=Activating tapdisk
[20131218T17:44:22.059Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|tapdisk_listen] Registered to listen to /dev/shm/1_1_f97ed720-a6ec-4822-82d9-95b20940cb5b.stats
[20131218T17:44:22.059Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|vhdSlave] Setting maxsize in shared page
[20131218T17:44:22.059Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|vhdSlave] Setting maxsize=58720256
[20131218T17:44:22.059Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:22.059Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|nmutex] wait: reason=Removing from master_approved_ops
[20131218T17:44:22.059Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|vhdSlave] Removing my current op
[20131218T17:44:22.059Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:22.059Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|nmutex] About to broadcast
[20131218T17:44:22.059Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|nmutex] Done
[20131218T17:44:22.059Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:22.059Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|nmutex] wait: reason=Removing from current_operations
[20131218T17:44:22.059Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|vhdSlave] Removing my current op
[20131218T17:44:22.059Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:22.059Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|nmutex] About to broadcast
[20131218T17:44:22.059Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|nmutex] Done
[20131218T17:44:22.060Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|33 inet-rpc|b91d7c6c-1f69-4cd5-9549-c1e89087b86c|vhdd] Response: (omitted)
[20131218T17:44:22.061Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|34 inet-rpc||http] Request { frame = false; method = POST; uri = /internal; query = [  ]; content_length = [ 144 ]; transfer encoding = ; version = 1.0; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = ; user_agent = xen-api-libs/1.0 }
[20131218T17:44:22.061Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|34 inet-rpc||vhdd] Internal handler
[20131218T17:44:22.061Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|34 inet-rpc||vhdd] Call={"method": "Debug.check_junk", "params": [{"sr": "1", "vdi": "f97ed720-a6ec-4822-82d9-95b20940cb5b", "current": [[[[0, 10]], 55]]}], "id": 1152}
[20131218T17:44:22.061Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|34 inet-rpc||vhdsm] Checking junk
[20131218T17:44:22.061Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|34 inet-rpc||vhdsm] Junk OK (1)
[20131218T17:44:22.061Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|34 inet-rpc||vhdd] Response: {"result": null, "error": null, "id": 0}
[20131218T17:44:22.062Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|35 inet-rpc||http] Request { frame = false; method = POST; uri = /internal; query = [  ]; content_length = [ 129 ]; transfer encoding = ; version = 1.0; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = ; user_agent = xen-api-libs/1.0 }
[20131218T17:44:22.062Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|35 inet-rpc||vhdd] Internal handler
[20131218T17:44:22.063Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|35 inet-rpc||vhdd] Call={"method": "Debug.check_junk", "params": [{"sr": "1", "vdi": "f97ed720-a6ec-4822-82d9-95b20940cb5b", "current": []}], "id": 1153}
[20131218T17:44:22.063Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|35 inet-rpc||vhdsm] Checking junk
[20131218T17:44:22.063Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|35 inet-rpc||vhdsm] Junk OK (0)
[20131218T17:44:22.063Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|35 inet-rpc||vhdd] Response: {"result": null, "error": null, "id": 0}
[20131218T17:44:22.064Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 415 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:22.064Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:22.064Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.deactivate</methodName><params><param><value><struct><member><name>dbg</name><value>dbg</value></member><member><name>dp</name><value>f97ed720-a6ec-4822-82d9-95b20940cb5b</value></member><member><name>sr</name><value>1</value></member><member><name>vdi</name><value>f97ed720-a6ec-4822-82d9-95b20940cb5b</value></member></struct></value></param></params></methodCall>
[20131218T17:44:22.064Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|vhdsm] API call: VDI.deactivate sr=1 vdi=f97ed720-a6ec-4822-82d9-95b20940cb5b
[20131218T17:44:22.064Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:22.064Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|nmutex] wait: reason=Adding to current_operations
[20131218T17:44:22.064Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|vhdSlave] Checking current ops
[20131218T17:44:22.064Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:22.065Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|nmutex] wait: reason=Deactivating
[20131218T17:44:22.065Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|tapdisk_listen] Unregistering 1/f97ed720-a6ec-4822-82d9-95b20940cb5b
[20131218T17:44:22.065Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.065Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|nmutex] wait: reason=Executing with operation '"OpDeactivating"'
[20131218T17:44:22.065Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.065Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|nmutex] wait: reason=Update id_map
[20131218T17:44:22.065Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|locking] update_leaf: vdi_location=f97ed720-a6ec-4822-82d9-95b20940cb5b
[20131218T17:44:22.065Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|nmutex] wait: reason=Finished op '"OpDeactivating"'. Removing from cur
[20131218T17:44:22.065Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|nmutex] About to broadcast
[20131218T17:44:22.065Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|nmutex] Done
[20131218T17:44:22.065Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:22.066Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|nmutex] wait: reason=Removing from current_operations
[20131218T17:44:22.066Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|vhdSlave] Removing my current op
[20131218T17:44:22.066Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:22.066Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|nmutex] About to broadcast
[20131218T17:44:22.066Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|nmutex] Done
[20131218T17:44:22.066Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|36 inet-rpc|b7488ac6-cac8-4c81-89c2-0cc9aaf7e2cf|vhdd] Response: (omitted)
[20131218T17:44:22.067Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 411 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:22.067Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:22.067Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.detach</methodName><params><param><value><struct><member><name>dbg</name><value>dbg</value></member><member><name>dp</name><value>f97ed720-a6ec-4822-82d9-95b20940cb5b</value></member><member><name>sr</name><value>1</value></member><member><name>vdi</name><value>f97ed720-a6ec-4822-82d9-95b20940cb5b</value></member></struct></value></param></params></methodCall>
[20131218T17:44:22.067Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|vhdsm] API call: VDI.detach sr=1 vdi=f97ed720-a6ec-4822-82d9-95b20940cb5b
[20131218T17:44:22.067Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:22.067Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|nmutex] wait: reason=Adding to current_operations
[20131218T17:44:22.067Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|vhdSlave] Checking current ops
[20131218T17:44:22.067Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:22.067Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|nmutex] wait: reason=Checking we're attached
[20131218T17:44:22.068Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|nmutex] wait: reason=Deactivating tapdisk if necessary
[20131218T17:44:22.068Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.068Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|nmutex] wait: reason=Executing with operation '"OpDetaching"'
[20131218T17:44:22.068Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.068Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|nmutex] wait: reason=Update id_map
[20131218T17:44:22.068Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|locking] update_leaf: vdi_location=f97ed720-a6ec-4822-82d9-95b20940cb5b
[20131218T17:44:22.068Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|nmutex] wait: reason=Getting VHD uid='46483369-750d-41f4-8409-6c83f65aabad'
[20131218T17:44:22.068Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|vhdMaster_utils] Resizing VHD uid: 46483369-750d-41f4-8409-6c83f65aabad
[20131218T17:44:22.068Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-566c9fd3-078c-4f14-81e2-c3ccdbc2f028
[20131218T17:44:22.069Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|mlvm] Using dm_name=a9ba8941-099d-4af8-ad3f-28570e1138ce (use_tmp=true)
[20131218T17:44:22.082Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|vhdutil] Dump size: overhead=4312576 phys_size=4312576 virtual_size=52428800 critical_size=56741376
[20131218T17:44:22.082Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|vhdutil] leaf_status: Some false reservation_type: Attach
[20131218T17:44:22.082Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-566c9fd3-078c-4f14-81e2-c3ccdbc2f028
[20131218T17:44:22.082Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|vhdMaster_utils] old_size=58720256 new_size=8388608
[20131218T17:44:22.082Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-566c9fd3-078c-4f14-81e2-c3ccdbc2f028
[20131218T17:44:22.082Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|mlvm] Beginning reduce_size_to:
[20131218T17:44:22.082Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|mlvm] Lv.reduce_size_to: s.s_start_extent=0 s.s_extent_count=2 left=2
[20131218T17:44:22.083Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|mlvm] LVM REDO: 000000000078„•¦¾   :          I¡	(VHD-566c9fd3-078c-4f14-81e2-c3ccdbc2f028_j        
[20131218T17:44:22.083Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-566c9fd3-078c-4f14-81e2-c3ccdbc2f028
[20131218T17:44:22.083Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-566c9fd3-078c-4f14-81e2-c3ccdbc2f028
[20131218T17:44:22.083Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|host] attach_lv: Got the mutex
[20131218T17:44:22.083Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|host] LV info has changed - altering dm tables
[20131218T17:44:22.083Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|host] oldty: Mlvm (VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028,{"m": [{"start": 0, "len": 16384, "map": ["Linear", {"device": ["Dereferenced", "HuQ48U-d2tF-atyS-Sxpy-7CRJ-kZBL-5ZS8AZ"], "offset": 274560}]}, {"start": 16384, "len": 98304, "map": ["Linear", {"device": ["Dereferenced", "HuQ48U-d2tF-atyS-Sxpy-7CRJ-kZBL-5ZS8AZ"], "offset": 290944}]}]})
[20131218T17:44:22.083Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|host] newty: Mlvm (VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028,{"m": [{"start": 0, "len": 16384, "map": ["Linear", {"device": ["Dereferenced", "HuQ48U-d2tF-atyS-Sxpy-7CRJ-kZBL-5ZS8AZ"], "offset": 274560}]}]})
[20131218T17:44:22.083Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|host] attach_lv: increasing refcount for dm=VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028 to 2
[20131218T17:44:22.083Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|host] attach_lv: released the mutex
[20131218T17:44:22.087Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|host] Remove LV: refcount for dm=VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028 is now 1
[20131218T17:44:22.087Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|nmutex] wait: reason=Finished op '"OpDetaching"'. Removing from cur
[20131218T17:44:22.087Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|nmutex] About to broadcast
[20131218T17:44:22.087Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|nmutex] Done
[20131218T17:44:22.087Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|vhdSlave] s_mutex lock: with_op_inner
[20131218T17:44:22.087Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|nmutex] wait: reason=Adding to master_approved_ops
[20131218T17:44:22.087Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|vhdSlave] Checking current ops
[20131218T17:44:22.087Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|vhdSlave] Adding my current op to the current_ops hashtbl
[20131218T17:44:22.087Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|nmutex] wait: reason=Reloading attach info
[20131218T17:44:22.087Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|host] Remove LV: refcount for dm=VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028 is now 0
[20131218T17:44:22.087Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|host] Removing LV=VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028
[20131218T17:44:22.087Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|host] Remove LV: refcount for dm=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549 is now 0
[20131218T17:44:22.087Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|host] Removing LV=VG_XenStorage--1-VHD--3b7ce781--fa29--42a4--ab34--e8655251f549
[20131218T17:44:22.088Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|nmutex] wait: reason=Removing attach info
[20131218T17:44:22.088Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:22.088Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|nmutex] wait: reason=Removing from master_approved_ops
[20131218T17:44:22.088Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|vhdSlave] Removing my current op
[20131218T17:44:22.088Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:22.088Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|nmutex] About to broadcast
[20131218T17:44:22.088Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|nmutex] Done
[20131218T17:44:22.088Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|vhdSlave] s_mutex lock: with_op_inner finally clause
[20131218T17:44:22.088Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|nmutex] wait: reason=Removing from current_operations
[20131218T17:44:22.088Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|vhdSlave] Removing my current op
[20131218T17:44:22.088Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|vhdSlave] Broadcasting to wake up other threads
[20131218T17:44:22.088Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|nmutex] About to broadcast
[20131218T17:44:22.088Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|nmutex] Done
[20131218T17:44:22.089Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|37 inet-rpc|4fe1b6c7-e288-4f5c-81f7-6a8af4bb6b13|vhdd] Response: (omitted)
[20131218T17:44:22.090Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 336 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:22.090Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:22.090Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.destroy</methodName><params><param><value><struct><member><name>dbg</name><value>delete_vdi</value></member><member><name>sr</name><value>1</value></member><member><name>vdi</name><value>f97ed720-a6ec-4822-82d9-95b20940cb5b</value></member></struct></value></param></params></methodCall>
[20131218T17:44:22.090Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|vhdsm] API call: VDI.delete sr=1 vdi=f97ed720-a6ec-4822-82d9-95b20940cb5b
[20131218T17:44:22.090Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|nmutex] wait: reason=Retrieving the hashtbl of attached hosts
[20131218T17:44:22.090Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.090Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|nmutex] wait: reason=Executing with operation '"OpDelete"'
[20131218T17:44:22.090Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.090Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|nmutex] wait: reason=Removing an ID from the mapping (f97ed720-a6ec-4822-82d9-95b20940cb5b)
[20131218T17:44:22.090Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|lvmabs] operating on vg: VG_XenStorage-1 lv: id_to_leaf_mapping
[20131218T17:44:22.091Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|host] attach_lv: Got the mutex
[20131218T17:44:22.091Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|host] LV VG_XenStorage--1-id_to_leaf_mapping not attached: attaching. refcount now 1
[20131218T17:44:22.091Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|mlvm] Using dm_name=VG_XenStorage--1-id_to_leaf_mapping (use_tmp=false)
[20131218T17:44:22.091Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|host] attach_lv: released the mutex
[20131218T17:44:22.091Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|host] Remove LV: refcount for dm=VG_XenStorage--1-id_to_leaf_mapping is now 0
[20131218T17:44:22.091Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|host] Removing LV=VG_XenStorage--1-id_to_leaf_mapping
[20131218T17:44:22.091Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|nmutex] wait: reason=Getting VHD uid='46483369-750d-41f4-8409-6c83f65aabad'
[20131218T17:44:22.091Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|vhdMaster_utils] Calling set_hidden on VHD uid=46483369-750d-41f4-8409-6c83f65aabad
[20131218T17:44:22.091Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-566c9fd3-078c-4f14-81e2-c3ccdbc2f028
[20131218T17:44:22.092Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|host] attach_lv: Got the mutex
[20131218T17:44:22.092Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|host] LV VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028 not attached: attaching. refcount now 1
[20131218T17:44:22.092Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|mlvm] Using dm_name=VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028 (use_tmp=false)
[20131218T17:44:22.092Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|host] attach_lv: released the mutex
[20131218T17:44:22.092Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|vhdutil] query_size_vhd: Querying size of VHD 46483369-750d-41f4-8409-6c83f65aabad
[20131218T17:44:22.092Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|vhdutil] query_size_vhd: get_phys_size returned 4312576
[20131218T17:44:22.092Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|vhdutil] query_size_vhd: first_allocated_block=None
[20131218T17:44:22.092Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|vhdutil] query_size_vhd: virtual_size=52428800
[20131218T17:44:22.096Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|host] Remove LV: refcount for dm=VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028 is now 0
[20131218T17:44:22.096Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|host] Removing LV=VG_XenStorage--1-VHD--566c9fd3--078c--4f14--81e2--c3ccdbc2f028
[20131218T17:44:22.096Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|nmutex] wait: reason=Update_hidden ptr='["PVhd", "46483369-750d-41f4-8409-6c83f65aabad"]' hidden=2
[20131218T17:44:22.096Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|nmutex] wait: reason=Removing VHD uid='46483369-750d-41f4-8409-6c83f65aabad'
[20131218T17:44:22.096Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-566c9fd3-078c-4f14-81e2-c3ccdbc2f028
[20131218T17:44:22.097Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|mlvm] LVM REDO: 000000000065„•¦¾   -          J”	(VHD-566c9fd3-078c-4f14-81e2-c3ccdbc2f028
[20131218T17:44:22.097Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|nmutex] wait: reason=Finished op '"OpDelete"'. Removing from cur
[20131218T17:44:22.097Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|nmutex] About to broadcast
[20131218T17:44:22.097Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|nmutex] Done
[20131218T17:44:22.097Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|38 inet-rpc|87654882-8610-4653-93d7-b46c90d0079c|vhdd] Response: (omitted)
[20131218T17:44:22.101Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 336 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:22.101Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:22.101Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>VDI.destroy</methodName><params><param><value><struct><member><name>dbg</name><value>delete_vdi</value></member><member><name>sr</name><value>1</value></member><member><name>vdi</name><value>04385b43-bc7b-4ca5-a23a-361c99f6189c</value></member></struct></value></param></params></methodCall>
[20131218T17:44:22.102Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|vhdsm] API call: VDI.delete sr=1 vdi=04385b43-bc7b-4ca5-a23a-361c99f6189c
[20131218T17:44:22.102Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|nmutex] wait: reason=Retrieving the hashtbl of attached hosts
[20131218T17:44:22.102Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.102Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|nmutex] wait: reason=Executing with operation '"OpDelete"'
[20131218T17:44:22.102Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|nmutex] wait: reason=Locked get leaf info
[20131218T17:44:22.102Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|nmutex] wait: reason=Removing an ID from the mapping (04385b43-bc7b-4ca5-a23a-361c99f6189c)
[20131218T17:44:22.102Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|lvmabs] operating on vg: VG_XenStorage-1 lv: id_to_leaf_mapping
[20131218T17:44:22.102Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|host] attach_lv: Got the mutex
[20131218T17:44:22.102Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|host] LV VG_XenStorage--1-id_to_leaf_mapping not attached: attaching. refcount now 1
[20131218T17:44:22.102Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|mlvm] Using dm_name=VG_XenStorage--1-id_to_leaf_mapping (use_tmp=false)
[20131218T17:44:22.102Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|host] attach_lv: released the mutex
[20131218T17:44:22.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|host] Remove LV: refcount for dm=VG_XenStorage--1-id_to_leaf_mapping is now 0
[20131218T17:44:22.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|host] Removing LV=VG_XenStorage--1-id_to_leaf_mapping
[20131218T17:44:22.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|nmutex] wait: reason=Getting VHD uid='e77c8668-3bd8-4b1c-9c02-7a90d9e5355a'
[20131218T17:44:22.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|vhdMaster_utils] Calling set_hidden on VHD uid=e77c8668-3bd8-4b1c-9c02-7a90d9e5355a
[20131218T17:44:22.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:22.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|host] attach_lv: Got the mutex
[20131218T17:44:22.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|host] LV VG_XenStorage--1-VHD--8c50892f--18da--49d0--ba1a--2253a5dd350b not attached: attaching. refcount now 1
[20131218T17:44:22.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|mlvm] Using dm_name=VG_XenStorage--1-VHD--8c50892f--18da--49d0--ba1a--2253a5dd350b (use_tmp=false)
[20131218T17:44:22.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|host] attach_lv: released the mutex
[20131218T17:44:22.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|vhdutil] query_size_vhd: Querying size of VHD e77c8668-3bd8-4b1c-9c02-7a90d9e5355a
[20131218T17:44:22.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|vhdutil] query_size_vhd: get_phys_size returned 4312576
[20131218T17:44:22.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|vhdutil] query_size_vhd: first_allocated_block=None
[20131218T17:44:22.103Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|vhdutil] query_size_vhd: virtual_size=52428800
[20131218T17:44:22.108Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|host] Remove LV: refcount for dm=VG_XenStorage--1-VHD--8c50892f--18da--49d0--ba1a--2253a5dd350b is now 0
[20131218T17:44:22.108Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|host] Removing LV=VG_XenStorage--1-VHD--8c50892f--18da--49d0--ba1a--2253a5dd350b
[20131218T17:44:22.108Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|nmutex] wait: reason=Update_hidden ptr='["PVhd", "e77c8668-3bd8-4b1c-9c02-7a90d9e5355a"]' hidden=2
[20131218T17:44:22.109Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|nmutex] wait: reason=Removing VHD uid='e77c8668-3bd8-4b1c-9c02-7a90d9e5355a'
[20131218T17:44:22.109Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|lvmabs] operating on vg: VG_XenStorage-1 lv: VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:22.109Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|mlvm] LVM REDO: 000000000065„•¦¾   -          K”	(VHD-8c50892f-18da-49d0-ba1a-2253a5dd350b
[20131218T17:44:22.109Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|nmutex] wait: reason=Finished op '"OpDelete"'. Removing from cur
[20131218T17:44:22.109Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|nmutex] About to broadcast
[20131218T17:44:22.109Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|nmutex] Done
[20131218T17:44:22.109Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|39 inet-rpc|9caa0eab-cce6-4648-b5a7-de3744683cf8|vhdd] Response: (omitted)
[20131218T17:44:22.113Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|40 inet-rpc||http] Request { frame = false; method = POST; uri = /lvmnew; query = [  ]; content_length = [ 250 ]; transfer encoding = ; version = 1.1; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = 127.0.0.1:4094; user_agent = ./ftests }
[20131218T17:44:22.114Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|40 inet-rpc||vhdd] path=lvmnew
[20131218T17:44:22.114Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|40 inet-rpc||vhdd] Request: <?xml version="1.0"?><methodCall><methodName>SR.detach</methodName><params><param><value><struct><member><name>dbg</name><value>detach_all</value></member><member><name>sr</name><value>1</value></member></struct></value></param></params></methodCall>
[20131218T17:44:22.114Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|40 inet-rpc|cf235536-b059-47fc-b6a0-fcd4dcae22be|lvmabs] operating on vg: VG_XenStorage-1 lv: host_attachments
[20131218T17:44:22.114Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|40 inet-rpc|cf235536-b059-47fc-b6a0-fcd4dcae22be|host] attach_lv: Got the mutex
[20131218T17:44:22.114Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|40 inet-rpc|cf235536-b059-47fc-b6a0-fcd4dcae22be|host] LV VG_XenStorage--1-host_attachments not attached: attaching. refcount now 1
[20131218T17:44:22.114Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|40 inet-rpc|cf235536-b059-47fc-b6a0-fcd4dcae22be|mlvm] Using dm_name=VG_XenStorage--1-host_attachments (use_tmp=false)
[20131218T17:44:22.115Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|40 inet-rpc|cf235536-b059-47fc-b6a0-fcd4dcae22be|host] attach_lv: released the mutex
[20131218T17:44:22.115Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|40 inet-rpc|cf235536-b059-47fc-b6a0-fcd4dcae22be|host] Remove LV: refcount for dm=VG_XenStorage--1-host_attachments is now 0
[20131218T17:44:22.115Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|40 inet-rpc|cf235536-b059-47fc-b6a0-fcd4dcae22be|host] Removing LV=VG_XenStorage--1-host_attachments
[20131218T17:44:22.115Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|40 inet-rpc|cf235536-b059-47fc-b6a0-fcd4dcae22be|mlvm] write_label_and_pv_header:
PV header:
pvh_id: HuQ48U-d2tF-atyS-Sxpy-7CRJ-kZBL-5ZS8AZ
pvh_device_size: 1099511627776
pvh_areas1: {offset=10551296,size=0}
pvh_areas2: {offset=4096,size=10547200}

[20131218T17:44:22.116Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|40 inet-rpc|cf235536-b059-47fc-b6a0-fcd4dcae22be|mlvm] Writing MDA header
[20131218T17:44:22.116Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|40 inet-rpc|cf235536-b059-47fc-b6a0-fcd4dcae22be|mlvm] Writing: checksum: -175619276
magic:  LVM2 x[5A%r0N*>
version: 1
start: 4096
size: 10485760
raw_locns:[{offset:2048,size:1455,checksum:104654034,filler:0}]

[20131218T17:44:22.116Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|40 inet-rpc|cf235536-b059-47fc-b6a0-fcd4dcae22be|host] remove_pv_id_info: Got mutex
[20131218T17:44:22.116Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|40 inet-rpc|cf235536-b059-47fc-b6a0-fcd4dcae22be|host] remove_pv_id_info: Released mutex
[20131218T17:44:22.116Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|40 inet-rpc|cf235536-b059-47fc-b6a0-fcd4dcae22be|vhdd] Response: (omitted)
[20131218T17:44:22.122Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|41 inet-rpc||http] Request { frame = false; method = POST; uri = /internal; query = [  ]; content_length = [ 67 ]; transfer encoding = ; version = 1.0; cookie = [ = ]; task = ; subtask_of = ; content-type = ; host = ; user_agent = xen-api-libs/1.0 }
[20131218T17:44:22.122Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|41 inet-rpc||vhdd] Internal handler
[20131218T17:44:22.122Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|41 inet-rpc||vhdd] Call={"method": "Debug.die", "params": [{"restart": false}], "id": 1154}
[20131218T17:44:22.122Z|debug|testing-worker-linux-7-2-6507-linux-19-15659603|41 inet-rpc||vhdsm] Got instruction to die with restart=false
[20131218T17:44:22.129Z| info|testing-worker-linux-7-2-6507-linux-19-15659603|0||watchdog] received exit code 0. Not restarting.
